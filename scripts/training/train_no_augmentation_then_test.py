"""
MEDAL-Lite å®Œæ•´æµç¨‹å»é™¤æ•°æ®å¢å¼ºè®­ç»ƒ+æµ‹è¯•è„šæœ¬
================================================
å®Œæ•´æµç¨‹ï¼šç‰¹å¾æå– -> æ ‡ç­¾çŸ«æ­£ -> åˆ†ç±»è®­ç»ƒï¼ˆä½¿ç”¨çŸ«æ­£åçš„æ•°æ®ï¼Œä¸è¿›è¡Œæ•°æ®å¢å¼ºï¼‰
"""
import os
import sys
from pathlib import Path

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

import json
import argparse
from datetime import datetime

import numpy as np
import torch
import random
import hashlib

from MoudleCode.utils.config import config
from MoudleCode.utils.helpers import set_seed, setup_logger, inject_label_noise
from MoudleCode.utils.logging_utils import (
    log_section_header, log_data_stats, log_input_paths, log_output_paths, log_final_summary
)
from MoudleCode.preprocessing.pcap_parser import load_dataset
from MoudleCode.feature_extraction.backbone import build_backbone

try:
    from scripts.utils.preprocess import check_preprocessed_exists, load_preprocessed, normalize_burstsize_inplace
    PREPROCESS_AVAILABLE = True
except Exception:
    PREPROCESS_AVAILABLE = False

from scripts.training.train import stage1_pretrain_backbone, stage2_label_correction_and_augmentation, stage3_finetune_classifier
from scripts.testing.test import main as test_main

# å¯¼å…¥æ ‡ç­¾çŸ«æ­£æ¨¡å—
from MoudleCode.label_correction.hybrid_court import HybridCourt
from MoudleCode.utils.logging_utils import log_stage_start, log_stage_end


def _safe_makedirs(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def _rng_fingerprint_short() -> str:
    h = hashlib.sha256()
    try:
        h.update(repr(random.getstate()).encode('utf-8'))
    except Exception:
        h.update(b'py_random_error')
    try:
        ns = np.random.get_state()
        h.update(str(ns[0]).encode('utf-8'))
        h.update(np.asarray(ns[1], dtype=np.uint32).tobytes())
        h.update(str(ns[2]).encode('utf-8'))
        h.update(str(ns[3]).encode('utf-8'))
        h.update(str(ns[4]).encode('utf-8'))
    except Exception:
        h.update(b'numpy_random_error')
    try:
        h.update(torch.get_rng_state().detach().cpu().numpy().tobytes())
    except Exception:
        h.update(b'torch_cpu_rng_error')
    try:
        if torch.cuda.is_available():
            for s in torch.cuda.get_rng_state_all():
                h.update(s.detach().cpu().numpy().tobytes())
        else:
            h.update(b'no_cuda')
    except Exception:
        h.update(b'torch_cuda_rng_error')
    return h.hexdigest()[:16]


def _seed_snapshot(args_seed: int) -> str:
    torch_seed = None
    try:
        torch_seed = int(torch.initial_seed())
    except Exception:
        torch_seed = None
    return (
        f"args.seed={int(args_seed)} | "
        f"config.SEED={int(getattr(config, 'SEED', -1))} | "
        f"torch.initial_seed={torch_seed}"
    )


def _load_train_dataset():
    """åŠ è½½è®­ç»ƒæ•°æ®é›†"""
    if PREPROCESS_AVAILABLE and check_preprocessed_exists('train'):
        X_train, y_train, _ = load_preprocessed('train')
        X_train = normalize_burstsize_inplace(X_train)
        return X_train, y_train

    X_train, y_train, _ = load_dataset(
        benign_dir=config.BENIGN_TRAIN,
        malicious_dir=config.MALICIOUS_TRAIN,
        sequence_length=config.SEQUENCE_LENGTH,
    )
    X_train = normalize_burstsize_inplace(X_train)
    return X_train, y_train


# æ³¨æ„ï¼šä¸å†éœ€è¦è‡ªå®šä¹‰çš„stage2å‡½æ•°ï¼Œç›´æ¥å¤ç”¨train.pyä¸­çš„stage2_label_correction_and_augmentation


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´æµç¨‹å»é™¤æ•°æ®å¢å¼ºè®­ç»ƒ+æµ‹è¯•")
    parser.add_argument('--retrain_backbone', action='store_true', help='é‡æ–°è®­ç»ƒéª¨å¹²ç½‘ç»œ')
    parser.add_argument('--backbone_path', type=str, default='', help='éª¨å¹²ç½‘ç»œè·¯å¾„')
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--run_tag', type=str, default='')
    args = parser.parse_args()

    rng_fp_before_seed = _rng_fingerprint_short()
    set_seed(args.seed)
    rng_fp_after_seed = _rng_fingerprint_short()
    config.create_dirs()
    logger = setup_logger(os.path.join(config.OUTPUT_ROOT, 'logs'), name='no_aug_train_test')

    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå‰): {rng_fp_before_seed}")
    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå): {rng_fp_after_seed} ({_seed_snapshot(args.seed)})")

    # é…ç½®ï¼šå»é™¤æ•°æ®å¢å¼º
    config.USE_FOCAL_LOSS = True
    config.USE_BCE_LOSS = False
    config.USE_SOFT_F1_LOSS = False
    config.STAGE3_ONLINE_AUGMENTATION = False
    config.STAGE3_USE_ST_MIXUP = False
    config.FINETUNE_BACKBONE = True  # å¯ç”¨éª¨å¹²å¾®è°ƒ
    config.FINETUNE_VAL_SPLIT = 0.0
    config.FINETUNE_ES_ALLOW_TRAIN_METRIC = True
    config.STAGE3_MIXED_STREAM = False  # ä¸ä½¿ç”¨æ··åˆè®­ç»ƒï¼ˆæ— å¢å¼ºæ•°æ®ï¼‰
    config.CLASSIFIER_INPUT_IS_FEATURES = False  # è¾“å…¥æ˜¯åŸå§‹åºåˆ—
    config.STAGE3_UNLABELED_LOSS_SCALE = 0.0  # ç¦ç”¨æ— æ ‡ç­¾æ•°æ®çš„åŠç›‘ç£å­¦ä¹ 
    config.STAGE2_USE_TABDDPM = False  # å…³é”®ï¼šç¦ç”¨TabDDPMæ•°æ®å¢å¼º

    run_tag = args.run_tag.strip() or datetime.now().strftime('%Y%m%d_%H%M%S')
    run_dir = os.path.join(config.LABEL_CORRECTION_DIR, 'analysis', 'no_augmentation_runs', run_tag)
    _safe_makedirs(run_dir)
    
    # éš”ç¦»è¾“å‡ºç›®å½•
    original_classification_dir = config.CLASSIFICATION_DIR
    original_result_dir = config.RESULT_DIR
    config.CLASSIFICATION_DIR = os.path.join(run_dir, 'classification')
    config.RESULT_DIR = os.path.join(run_dir, 'result')
    
    for d in [config.CLASSIFICATION_DIR, config.RESULT_DIR]:
        _safe_makedirs(d)
        _safe_makedirs(os.path.join(d, 'models'))
        _safe_makedirs(os.path.join(d, 'figures'))
        _safe_makedirs(os.path.join(d, 'logs'))

    try:
        log_section_header(logger, "ğŸš€ å®Œæ•´æµç¨‹å»é™¤æ•°æ®å¢å¼ºæ¨¡å¼")
        logger.info(f'è¿è¡Œç›®å½•: {run_dir}')
        logger.info(f'æ—¶é—´æˆ³: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        logger.info('')
        logger.info('ğŸ“‹ è®­ç»ƒæ¨¡å¼è¯´æ˜:')
        logger.info('  - Stage 1: éª¨å¹²ç½‘ç»œé¢„è®­ç»ƒï¼ˆç‰¹å¾æå–ï¼‰')
        logger.info('  - Stage 2: æ ‡ç­¾çŸ«æ­£ï¼ˆæ— æ•°æ®å¢å¼ºï¼‰')
        logger.info('  - Stage 3: åˆ†ç±»å™¨è®­ç»ƒï¼ˆä½¿ç”¨çŸ«æ­£åçš„åŸå§‹æ•°æ®ï¼‰')
        logger.info('  - æ•°æ®å¢å¼º: å®Œå…¨è·³è¿‡')
        logger.info('  - éª¨å¹²å¾®è°ƒ: å¯ç”¨')
        logger.info('')
        
        # åŠ è½½æ•°æ®
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½è®­ç»ƒæ•°æ®å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        X_train, y_train_clean = _load_train_dataset()
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½è®­ç»ƒæ•°æ®å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        if X_train is None:
            raise RuntimeError('è®­ç»ƒæ•°æ®é›†åŠ è½½å¤±è´¥')

        # æ³¨å…¥æ ‡ç­¾å™ªå£°
        logger.info(f"ğŸ”€ æ³¨å…¥æ ‡ç­¾å™ªå£° ({config.LABEL_NOISE_RATE*100:.0f}%)...")
        y_train_noisy, noise_mask = inject_label_noise(y_train_clean, config.LABEL_NOISE_RATE)
        logger.info(f"âœ“ å™ªå£°æ ‡ç­¾åˆ›å»ºå®Œæˆ: {noise_mask.sum()} ä¸ªæ ‡ç­¾è¢«ç¿»è½¬")

        log_data_stats(logger, {
            "æ•°æ®å½¢çŠ¶": f"{X_train.shape}",
            "è®­ç»ƒæ ·æœ¬æ€»æ•°": len(X_train),
            "æ­£å¸¸æ ·æœ¬ï¼ˆçœŸå®ï¼‰": int((y_train_clean == 0).sum()),
            "æ¶æ„æ ·æœ¬ï¼ˆçœŸå®ï¼‰": int((y_train_clean == 1).sum()),
            "æ­£å¸¸æ ·æœ¬ï¼ˆå™ªå£°ï¼‰": int((y_train_noisy == 0).sum()),
            "æ¶æ„æ ·æœ¬ï¼ˆå™ªå£°ï¼‰": int((y_train_noisy == 1).sum()),
            "å™ªå£°æ ‡ç­¾æ•°": int(noise_mask.sum()),
            "å™ªå£°ç‡": f"{config.LABEL_NOISE_RATE*100:.1f}%"
        }, "è®­ç»ƒæ•°æ®ç»Ÿè®¡")
        
        # Stage 1: éª¨å¹²ç½‘ç»œè®­ç»ƒæˆ–åŠ è½½
        backbone = None
        backbone_path = args.backbone_path if args.backbone_path else os.path.join(
            config.FEATURE_EXTRACTION_DIR, 'models', 'backbone_pretrained.pth'
        )
        
        if args.retrain_backbone or not os.path.exists(backbone_path):
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1è°ƒç”¨å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            backbone = stage1_pretrain_backbone(X_train, config, logger)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1è¿”å›å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            
            if backbone is not None:
                torch.save(backbone.state_dict(), backbone_path)
                logger.info(f'âœ“ å·²ä¿å­˜æ–°éª¨å¹²ç½‘ç»œ: {backbone_path}')
        else:
            logger.info(f'âœ“ ä½¿ç”¨å·²æœ‰éª¨å¹²ç½‘ç»œ: {backbone_path}')
        
        # åŠ è½½éª¨å¹²ç½‘ç»œ
        if backbone is None:
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æ„å»ºbackboneå‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            backbone = build_backbone(config, logger=logger)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æ„å»ºbackboneå): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            
            if os.path.exists(backbone_path):
                logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½backboneæƒé‡å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
                try:
                    state_dict = torch.load(backbone_path, map_location=config.DEVICE, weights_only=True)
                except TypeError:
                    state_dict = torch.load(backbone_path, map_location=config.DEVICE)
                backbone.load_state_dict(state_dict, strict=False)
                logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½backboneæƒé‡å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            else:
                logger.warning('âš  éª¨å¹²ç½‘ç»œæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨éšæœºåˆå§‹åŒ–')
        
        backbone.to(config.DEVICE)
        backbone.freeze()
        
        # Stage 2: æ ‡ç­¾çŸ«æ­£ï¼ˆç›´æ¥å¤ç”¨å®Œæ•´æµç¨‹çš„å‡½æ•°ï¼Œä½†ç¦ç”¨TabDDPMï¼‰
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage2è°ƒç”¨å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        
        # ç›´æ¥è°ƒç”¨å®Œæ•´æµç¨‹çš„stage2å‡½æ•°ï¼Œé€šè¿‡config.STAGE2_USE_TABDDPM=Falseè·³è¿‡æ•°æ®å¢å¼º
        Z_augmented, y_augmented, sample_weights, correction_stats, tabddpm, n_original = stage2_label_correction_and_augmentation(
            backbone, X_train, y_train_noisy, y_train_clean, config, logger
        )
        
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage2è¿”å›å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        
        # ç”±äºç¦ç”¨äº†TabDDPMï¼ŒZ_augmentedå®é™…ä¸Šæ˜¯ç‰¹å¾ï¼Œy_augmentedæ˜¯çŸ«æ­£åçš„æ ‡ç­¾
        # æˆ‘ä»¬éœ€è¦ä½¿ç”¨åŸå§‹åºåˆ—X_trainè¿›è¡ŒStage3è®­ç»ƒ
        logger.info(f"âœ“ Stage2å®Œæˆ: ç‰¹å¾å½¢çŠ¶={Z_augmented.shape}, æ ‡ç­¾å½¢çŠ¶={y_augmented.shape}")
        logger.info(f"âœ“ çŸ«æ­£å‡†ç¡®ç‡: {correction_stats['accuracy']*100:.2f}%")
        
        # Stage 3éœ€è¦åŸå§‹åºåˆ—ï¼Œä¸æ˜¯ç‰¹å¾
        # æ‰€ä»¥æˆ‘ä»¬ä¼ å…¥X_trainï¼ˆåŸå§‹åºåˆ—ï¼‰å’Œy_augmentedï¼ˆçŸ«æ­£åçš„æ ‡ç­¾ï¼‰
        X_for_stage3 = X_train
        y_for_stage3 = y_augmented
        weights_for_stage3 = sample_weights
        
        # Stage 3: åˆ†ç±»å™¨è®­ç»ƒ
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage3è°ƒç”¨å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        stage3_finetune_classifier(
            backbone, X_for_stage3, y_for_stage3, weights_for_stage3,
            config, logger, n_original=n_original, backbone_path=backbone_path
        )
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage3è¿”å›å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

        # æµ‹è¯•
        log_section_header(logger, "ğŸ§ª æµ‹è¯•è¯„ä¼°")
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æµ‹è¯•å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        classifier_best = os.path.join(config.CLASSIFICATION_DIR, 'models', 'classifier_best_f1.pth')
        
        meta_path = os.path.join(config.CLASSIFICATION_DIR, 'models', 'model_metadata.json')
        backbone_path_for_test = backbone_path
        if os.path.exists(meta_path):
            with open(meta_path, 'r') as f:
                meta = json.load(f)
            bp = meta.get('backbone_path', '')
            if bp:
                if os.path.exists(bp):
                    backbone_path_for_test = bp
                    logger.info(f"âœ“ ä½¿ç”¨å…ƒæ•°æ®ä¸­è®°å½•çš„éª¨å¹²ç½‘ç»œ: {bp}")
                else:
                    logger.warning(f"âš  å…ƒæ•°æ®ä¸­è®°å½•çš„éª¨å¹²ç½‘ç»œä¸å­˜åœ¨: {bp}")
                    logger.warning(f"  å›é€€åˆ°è®­ç»ƒæ—¶ä½¿ç”¨çš„éª¨å¹²ç½‘ç»œ: {backbone_path}")

        test_args = argparse.Namespace(backbone_path=backbone_path_for_test)
        test_main(test_args)
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æµ‹è¯•å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

        log_final_summary(logger, "å®Œæˆ", {
            "çŸ«æ­£å‡†ç¡®ç‡": f"{correction_stats['accuracy']*100:.2f}%",
            "ä¿æŒæ ·æœ¬": correction_stats['n_keep'],
            "ç¿»è½¬æ ·æœ¬": correction_stats['n_flip'],
            "ä¸¢å¼ƒæ ·æœ¬": correction_stats['n_drop'],
            "é‡åŠ æƒæ ·æœ¬": correction_stats['n_reweight']
        }, {
            "è¿è¡Œç›®å½•": run_dir,
            "åˆ†ç±»å™¨": classifier_best,
            "æµ‹è¯•ç»“æœ": config.RESULT_DIR
        })
        
    finally:
        config.CLASSIFICATION_DIR = original_classification_dir
        config.RESULT_DIR = original_result_dir


if __name__ == '__main__':
    main()
