"""
MLæŠ•ç¥¨æ ‡ç­¾çŸ«æ­£å®éªŒ
==================

ä½¿ç”¨å¤šä¸ªæœºå™¨å­¦ä¹ æ¨¡å‹å¯¹ä½è´¨é‡æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨çŸ«æ­£ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨ã€‚

åŠŸèƒ½:
1. åŸºäºè´¨é‡åˆ†æ•°å°†æ ·æœ¬åˆ†ä¸ºé«˜è´¨é‡å’Œä½è´¨é‡ä¸¤ç»„
2. ä½¿ç”¨é«˜è´¨é‡æ ·æœ¬è®­ç»ƒå¤šä¸ªMLæ¨¡å‹
3. å¯¹ä½è´¨é‡æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨çŸ«æ­£
4. ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œå¯è§†åŒ–å›¾è¡¨

è¾“å‡º:
- output/report.txt          - è¯¦ç»†åˆ†ææŠ¥å‘Š
- output/figures/            - å¯è§†åŒ–å›¾è¡¨
- output/summary.json        - å®éªŒæ‘˜è¦
"""
import argparse
import os
import sys
import json
import logging
import csv
from datetime import datetime
import numpy as np
import torch
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib import font_manager
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.manifold import TSNE
from sklearn.pipeline import Pipeline
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
from sklearn.linear_model import LogisticRegression
import torch.nn as nn

PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from MoudleCode.utils.config import config
from MoudleCode.label_correction.hybrid_court import HybridCourt
from MoudleCode.label_correction.hybrid_court_experimental import HybridCourtExperimental
from MoudleCode.feature_extraction.backbone import MicroBiMambaBackbone
from MoudleCode.utils.helpers import inject_label_noise, calculate_metrics, set_seed

try:
    from preprocess import check_preprocessed_exists, load_preprocessed
    PREPROCESS_AVAILABLE = True
except ImportError:
    PREPROCESS_AVAILABLE = False

# é…ç½®ä¸­æ–‡å­—ä½“
def _configure_matplotlib_chinese_fonts():
    try:
        # ç›´æ¥ä½¿ç”¨å¯ç”¨çš„ä¸­æ–‡å­—ä½“
        mpl.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'Noto Serif CJK JP', 'Noto Mono']
        mpl.rcParams['axes.unicode_minus'] = False
        # æ¸…é™¤å­—ä½“ç¼“å­˜
        font_manager._rebuild()
    except Exception:
        pass

_configure_matplotlib_chinese_fonts()


# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


def _softmax_max_prob(pred_probs: np.ndarray) -> np.ndarray:
    if pred_probs.ndim != 2:
        raise ValueError(f"pred_probs must have shape (N, C), got {pred_probs.shape}")
    return np.max(pred_probs, axis=1)


def _minmax01(x: np.ndarray, eps: float = 1e-12) -> np.ndarray:
    x = np.asarray(x)
    mn = np.nanmin(x)
    mx = np.nanmax(x)
    if not np.isfinite(mn) or not np.isfinite(mx) or (mx - mn) < eps:
        return np.zeros_like(x, dtype=np.float32)
    return ((x - mn) / (mx - mn + eps)).astype(np.float32)


def _to_jsonable(obj):
    if isinstance(obj, np.ndarray):
        return obj.tolist()
    if isinstance(obj, (np.floating, np.integer)):
        return obj.item()
    if isinstance(obj, dict):
        return {k: _to_jsonable(v) for k, v in obj.items()}
    if isinstance(obj, (list, tuple)):
        return [_to_jsonable(v) for v in obj]
    return obj


def _build_models(random_state: int):
    """æ„å»ºå¤šä¸ªMLæ¨¡å‹"""
    from sklearn.naive_bayes import GaussianNB
    from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
    from sklearn.svm import SVC
    from sklearn.linear_model import LogisticRegression
    from sklearn.pipeline import Pipeline
    from sklearn.preprocessing import StandardScaler

    models = {}
    models["GaussianNB"] = GaussianNB()
    models["AdaBoost"] = AdaBoostClassifier(random_state=random_state)
    models["LDA"] = LinearDiscriminantAnalysis()
    models["SVM"] = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", SVC(probability=True, kernel="rbf", C=1.0, gamma="scale", random_state=random_state))
    ])
    models["RandomForest"] = RandomForestClassifier(n_estimators=400, random_state=random_state, n_jobs=-1)
    models["LogisticRegression"] = Pipeline([
        ("scaler", StandardScaler()),
        ("clf", LogisticRegression(max_iter=2000, solver="lbfgs", random_state=random_state))
    ])

    try:
        from xgboost import XGBClassifier
        models["XGBoost"] = XGBClassifier(
            n_estimators=500, max_depth=6, learning_rate=0.05,
            subsample=0.9, colsample_bytree=0.9, reg_lambda=1.0,
            objective="binary:logistic", eval_metric="logloss",
            n_jobs=-1, random_state=random_state, verbosity=0
        )
    except Exception:
        models["XGBoost"] = GradientBoostingClassifier(random_state=random_state)

    return models


def _fit_estimator(model, X, y, sample_weight=None):
    if sample_weight is None:
        model.fit(X, y)
        return
    try:
        model.fit(X, y, sample_weight=sample_weight)
        return
    except ValueError:
        if isinstance(model, Pipeline) and len(model.steps) > 0:
            last_step_name = model.steps[-1][0]
            model.fit(X, y, **{f"{last_step_name}__sample_weight": sample_weight})
            return
        model.fit(X, y)
        return
    except TypeError:
        model.fit(X, y)


def _predict_proba_pos1(model, X: np.ndarray) -> np.ndarray:
    if hasattr(model, "predict_proba"):
        p = model.predict_proba(X)
        if p.ndim == 2 and p.shape[1] >= 2:
            return p[:, 1].astype(np.float32)
    if hasattr(model, "decision_function"):
        s = model.decision_function(X)
        s = np.asarray(s).astype(np.float32)
        return (1.0 / (1.0 + np.exp(-s))).astype(np.float32)
    return model.predict(X).astype(np.float32)


def _predict_proba_matrix(fitted: dict, X: np.ndarray) -> tuple:
    names = list(fitted.keys())
    mats = []
    for name, model in fitted.items():
        mats.append(_predict_proba_pos1(model, X))
    mat = np.stack(mats, axis=1) if mats else np.zeros((len(X), 0), dtype=np.float32)
    return mat, names


def _stacked_predict_proba(models: dict, X_train: np.ndarray, y_train: np.ndarray, X_vote: np.ndarray, seed: int, sample_weight=None) -> np.ndarray:
    names = list(models.keys())
    n_models = len(names)
    oof = np.zeros((len(X_train), n_models), dtype=np.float32)
    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)
    for tr_idx, va_idx in skf.split(X_train, y_train):
        X_tr, y_tr = X_train[tr_idx], y_train[tr_idx]
        X_va = X_train[va_idx]
        w_tr = sample_weight[tr_idx] if sample_weight is not None else None
        for mi, name in enumerate(names):
            est = clone(models[name])
            _fit_estimator(est, X_tr, y_tr, sample_weight=w_tr)
            oof[va_idx, mi] = _predict_proba_pos1(est, X_va)
    meta = LogisticRegression(max_iter=2000, solver="lbfgs", random_state=seed)
    meta.fit(oof, y_train)
    base_vote = np.zeros((len(X_vote), n_models), dtype=np.float32)
    for mi, name in enumerate(names):
        est = clone(models[name])
        _fit_estimator(est, X_train, y_train, sample_weight=sample_weight)
        base_vote[:, mi] = _predict_proba_pos1(est, X_vote)
    return meta.predict_proba(base_vote)[:, 1].astype(np.float32)


def _mlp_predict_proba(X_train: np.ndarray, y_train: np.ndarray, X_vote: np.ndarray, seed: int, device, sample_weight=None,
                      hidden: int = 128, epochs: int = 200, lr: float = 1e-3, weight_decay: float = 1e-4,
                      batch_size: int = 64) -> np.ndarray:
    torch.manual_seed(seed)
    np.random.seed(seed)

    X_train_t = torch.as_tensor(X_train, dtype=torch.float32, device=device)
    y_train_t = torch.as_tensor(y_train.astype(np.float32), dtype=torch.float32, device=device).view(-1, 1)
    X_vote_t = torch.as_tensor(X_vote, dtype=torch.float32, device=device)
    if sample_weight is None:
        w_t = torch.ones((len(X_train_t), 1), dtype=torch.float32, device=device)
    else:
        w = np.asarray(sample_weight, dtype=np.float32).reshape(-1, 1)
        w_t = torch.as_tensor(w, dtype=torch.float32, device=device)

    d = X_train_t.shape[1]
    model = nn.Sequential(
        nn.Linear(d, hidden),
        nn.ReLU(),
        nn.Dropout(p=0.1),
        nn.Linear(hidden, 1),
    ).to(device)

    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    loss_fn = nn.BCEWithLogitsLoss(reduction="none")

    idx = torch.arange(len(X_train_t), device=device)
    for _ in range(int(epochs)):
        perm = idx[torch.randperm(len(idx))]
        for start in range(0, len(perm), batch_size):
            b = perm[start:start + batch_size]
            xb = X_train_t[b]
            yb = y_train_t[b]
            wb = w_t[b]
            logits = model(xb)
            loss = loss_fn(logits, yb)
            loss = (loss * wb).mean()
            opt.zero_grad()
            loss.backward()
            opt.step()

    model.eval()
    with torch.no_grad():
        logits = model(X_vote_t)
        prob = torch.sigmoid(logits).view(-1).detach().cpu().numpy().astype(np.float32)
    return prob


def _extract_backbone_features(backbone: MicroBiMambaBackbone, X: np.ndarray, device, logger, batch_size: int = 64) -> np.ndarray:
    backbone.to(device)
    backbone.freeze()
    backbone.eval()

    feats = []
    with torch.no_grad():
        X_tensor = torch.as_tensor(X, dtype=torch.float32, device=device)
        total_batches = (len(X_tensor) + batch_size - 1) // batch_size
        for bi, start in enumerate(range(0, len(X_tensor), batch_size), start=1):
            X_batch = X_tensor[start:start + batch_size]
            z = backbone(X_batch, return_sequence=False)
            feats.append(z.detach().cpu().numpy())
            if bi % 10 == 0 or bi == total_batches:
                logger.info(f"  ç‰¹å¾æå–è¿›åº¦: {bi}/{total_batches} batches ({bi/total_batches*100:.1f}%)")

    return np.concatenate(feats, axis=0) if feats else np.empty((0, 0), dtype=np.float32)


def _run_from_preprocessed(args, logger):
    if not PREPROCESS_AVAILABLE:
        logger.error("âŒ æ— æ³•å¯¼å…¥ preprocess.pyï¼ˆæ— æ³•åŠ è½½é¢„å¤„ç†æ•°æ®ï¼‰ã€‚è¯·ç¡®ä¿ä»é¡¹ç›®æ ¹ç›®å½•è¿è¡Œã€‚")
        return

    set_seed(args.seed)

    reuse_cache_dir = str(getattr(args, 'reuse_cache_dir', '') or '')
    save_cache_dir = str(getattr(args, 'save_cache_dir', '') or '')

    if reuse_cache_dir:
        cache_dir = reuse_cache_dir
        logger.info("æ­¥éª¤1: å¤ç”¨ç¼“å­˜ï¼ˆè·³è¿‡ç‰¹å¾æå–ä¸HybridCourtï¼‰")
        logger.info("-"*70)
        required = [
            "features.npy",
            "y_true.npy",
            "y_noisy.npy",
            "y_corrected_hc.npy",
            "action_mask.npy",
            "correction_weight.npy",
        ]
        missing = [fn for fn in required if not os.path.exists(os.path.join(cache_dir, fn))]
        if missing:
            logger.error(f"âŒ reuse_cache_dir ç¼ºå°‘æ–‡ä»¶: {missing} (dir={cache_dir})")
            return

        features = np.load(os.path.join(cache_dir, "features.npy"))
        y_true = np.load(os.path.join(cache_dir, "y_true.npy")).astype(int)
        y_noisy = np.load(os.path.join(cache_dir, "y_noisy.npy")).astype(int)
        y_corrected = np.load(os.path.join(cache_dir, "y_corrected_hc.npy")).astype(int)
        action_mask = np.load(os.path.join(cache_dir, "action_mask.npy")).astype(int)
        correction_weight = np.load(os.path.join(cache_dir, "correction_weight.npy")).astype(np.float32)
        noise_mask = (y_noisy != y_true)
        features_source = os.path.join(cache_dir, "features.npy")
    else:
        if not check_preprocessed_exists(args.data_split):
            logger.error(f"âŒ é¢„å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨: output/preprocessed/{args.data_split}_X.npy ç­‰")
            return

        X_seq, y_true, _ = load_preprocessed(args.data_split)
        y_true = y_true.astype(int)

        if args.noise_rate > 0:
            y_noisy, noise_mask = inject_label_noise(y_true, args.noise_rate, num_classes=2)
        else:
            y_noisy = y_true.copy()
            noise_mask = np.zeros(len(y_true), dtype=bool)

        if args.features_npy:
            if not os.path.exists(args.features_npy):
                logger.error(f"âŒ features_npy ä¸å­˜åœ¨: {args.features_npy}")
                return
            features = np.load(args.features_npy)
            features_source = args.features_npy
        else:
            backbone_path = args.backbone or os.path.join(config.FEATURE_EXTRACTION_DIR, "models", "backbone_pretrained.pth")
            if not os.path.exists(backbone_path):
                logger.error(f"âŒ backbone æƒé‡ä¸å­˜åœ¨: {backbone_path}")
                return
            backbone = MicroBiMambaBackbone(config)
            backbone.load_state_dict(torch.load(backbone_path, map_location=config.DEVICE))
            features_source = backbone_path
            logger.info("æ­¥éª¤2: ç‰¹å¾æå–")
            logger.info("-"*70)
            features = _extract_backbone_features(backbone, X_seq, config.DEVICE, logger, batch_size=64)

    if len(features) != len(y_true):
        logger.error(f"âŒ ç‰¹å¾æ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸ä¸€è‡´: features={len(features)}, labels={len(y_true)}")
        return

    if not reuse_cache_dir:
        logger.info("æ­¥éª¤3: HybridCourt æ ‡ç­¾çŸ«æ­£")
        logger.info("-"*70)
        if getattr(args, 'hc_impl', 'experimental') == 'original':
            hybrid_court = HybridCourt(config)
        else:
            hybrid_court = HybridCourtExperimental(config)
        y_corrected, action_mask, _, correction_weight, _, _, _ = hybrid_court.correct_labels(
            features, y_noisy, device=config.DEVICE
        )

        if save_cache_dir:
            os.makedirs(save_cache_dir, exist_ok=True)
            np.save(os.path.join(save_cache_dir, "features.npy"), features)
            np.save(os.path.join(save_cache_dir, "y_true.npy"), y_true)
            np.save(os.path.join(save_cache_dir, "y_noisy.npy"), y_noisy)
            np.save(os.path.join(save_cache_dir, "y_corrected_hc.npy"), y_corrected)
            np.save(os.path.join(save_cache_dir, "action_mask.npy"), action_mask.astype(np.int32))
            np.save(os.path.join(save_cache_dir, "correction_weight.npy"), correction_weight.astype(np.float32))
            meta = {
                "seed": int(args.seed),
                "noise_rate": float(args.noise_rate),
                "data_split": str(args.data_split),
                "hc_impl": str(getattr(args, 'hc_impl', 'experimental')),
                "features_source": str(features_source),
            }
            with open(os.path.join(save_cache_dir, "cache_meta.json"), "w", encoding="utf-8") as f:
                json.dump(meta, f, ensure_ascii=False, indent=2)

    if args.train_on == "keep":
        keep_mask = action_mask == 0
    elif args.train_on == "keep_flip":
        keep_mask = (action_mask == 0) | (action_mask == 1)
    else:
        keep_mask = action_mask != 2

    # é»˜è®¤ä»…å¯¹ Reweight(action=3) åšæŠ•ç¥¨çŸ«æ­£ï¼›å¯é€‰æŠŠ Drop(action=2) ä¹ŸåŠ å…¥ï¼ˆé«˜ç½®ä¿¡è¦†ç›–ï¼‰
    if getattr(args, 'vote_include_drop', False):
        vote_mask = ((action_mask == 3) | (action_mask == 2)) & (~keep_mask)
    else:
        vote_mask = (action_mask == 3) & (~keep_mask)

    idx_keep = np.where(keep_mask)[0]
    idx_vote = np.where(vote_mask)[0]
    idx_rest = np.where(~keep_mask)[0]

    logger.info("æ­¥éª¤4: åˆ’åˆ†Keepæ ·æœ¬ä¸å¾…é¢„æµ‹æ ·æœ¬")
    logger.info("-"*70)
    logger.info(f"  æ€»æ ·æœ¬æ•°: {len(y_true)}")
    logger.info(f"  çœŸå®æ ‡ç­¾åˆ†å¸ƒ: æ­£å¸¸={(y_true==0).sum()} æ¶æ„={(y_true==1).sum()}")
    logger.info(f"  æ³¨å…¥å™ªå£°æ ·æœ¬: {int(noise_mask.sum())}/{len(y_true)} (rate={args.noise_rate:.2f})")
    logger.info(f"  Keepæ ·æœ¬(è®­ç»ƒ): {len(idx_keep)} ({100*len(idx_keep)/len(y_true):.1f}%)")
    logger.info(f"  å…¶ä½™æ ·æœ¬(éè®­ç»ƒ): {len(idx_rest)} ({100*len(idx_rest)/len(y_true):.1f}%)")
    logger.info(f"  æŠ•ç¥¨çŸ«æ­£æ ·æœ¬(Reweight): {len(idx_vote)} ({100*len(idx_vote)/len(y_true):.1f}%)")
    logger.info("")
    
    if len(idx_keep) == 0:
        logger.error("âŒ Keepæ ·æœ¬ä¸ºç©ºï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹ã€‚è¯·å°è¯• --train_on nondrop")
        return
    
    rng = np.random.default_rng(args.seed)
    X_train = features[idx_keep]
    y_train = y_corrected[idx_keep].astype(int)
    train_sample_weight = correction_weight[idx_keep].astype(float)

    if args.train_on == "keep_flip":
        flip_in_train = (action_mask[idx_keep] == 1)
        if flip_in_train.any():
            train_sample_weight = train_sample_weight.copy()
            train_sample_weight[flip_in_train] *= float(getattr(args, "flip_train_weight", 0.5))

    if args.balance_train:
        idx0 = idx_keep[y_train == 0]
        idx1 = idx_keep[y_train == 1]
        n = min(len(idx0), len(idx1))
        if n > 0:
            idx0_s = rng.choice(idx0, size=n, replace=False)
            idx1_s = rng.choice(idx1, size=n, replace=False)
            idx_bal = np.concatenate([idx0_s, idx1_s])
            rng.shuffle(idx_bal)
            X_train = features[idx_bal]
            y_train = y_corrected[idx_bal].astype(int)
            train_sample_weight = correction_weight[idx_bal].astype(float)

            if args.train_on == "keep_flip":
                flip_in_train = (action_mask[idx_bal] == 1)
                if flip_in_train.any():
                    train_sample_weight = train_sample_weight.copy()
                    train_sample_weight[flip_in_train] *= float(getattr(args, "flip_train_weight", 0.5))

    logger.info("æ­¥éª¤5: è®­ç»ƒMLæ¨¡å‹")
    logger.info("-"*70)
    
    models = _build_models(args.seed)
    logger.info(f"  ä½¿ç”¨ {len(models)} ä¸ªæ¨¡å‹: {list(models.keys())}")
    logger.info("")
    fitted, accuracies = _fit_models(models, X_train, y_train, logger, sample_weight=train_sample_weight)
    logger.info("")
    
    logger.info("æ­¥éª¤6: å¯¹å…¶ä½™æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨é¢„æµ‹")
    logger.info("-"*70)
    X_vote = features[idx_vote]
    model_names = list(fitted.keys())
    if len(idx_vote) == 0:
        vote_mat = np.zeros((0, len(model_names)), dtype=int)
        vote_sum = np.zeros((0,), dtype=int)
        score = np.zeros((0,), dtype=np.float32)
        y_vote_hard = np.zeros((0,), dtype=int)
        vote_rule = getattr(args, "vote_rule", "hard")
        band_low = int(getattr(args, "band_low", -1))
        band_high = int(getattr(args, "band_high", len(model_names) + 1))
        vote_score = getattr(args, "vote_score", "count")
        prob_threshold = float(getattr(args, "prob_threshold", 0.5))
        prob_low = float(getattr(args, "prob_low", 0.3))
        prob_high = float(getattr(args, "prob_high", 0.7))
        vote_apply_local = np.zeros((0,), dtype=bool)
        y_vote_final = np.zeros((0,), dtype=int)
        vote_distribution = [0] * (len(model_names) + 1)
        model_malicious_ratio = {n: 0.0 for n in model_names}

        y_pred_all = y_corrected.copy()
        metrics_vote = None
        report_vote = ""
    else:
        vote_mat, _ = _vote_predict(fitted, X_vote)
        vote_sum = vote_mat.sum(axis=1) if vote_mat.size else np.zeros((len(X_vote),), dtype=int)

        vote_score = getattr(args, "vote_score", "count")
        prob_threshold = float(getattr(args, "prob_threshold", 0.5))
        prob_low = float(getattr(args, "prob_low", 0.3))
        prob_high = float(getattr(args, "prob_high", 0.7))

        mlp_hidden = int(getattr(args, "mlp_hidden", 128))
        mlp_epochs = int(getattr(args, "mlp_epochs", 200))
        mlp_lr = float(getattr(args, "mlp_lr", 1e-3))
        mlp_weight_decay = float(getattr(args, "mlp_weight_decay", 1e-4))

        proba_mat, _ = _predict_proba_matrix(fitted, X_vote)
        mean_proba = proba_mat.mean(axis=1).astype(np.float32) if proba_mat.size else np.zeros((len(X_vote),), dtype=np.float32)
        stacked_proba = None
        if vote_score == "stacked":
            stacked_proba = _stacked_predict_proba(models, X_train, y_train, X_vote, seed=args.seed, sample_weight=train_sample_weight)
        mlp_proba = None
        if vote_score == "mlp":
            mlp_proba = _mlp_predict_proba(
                X_train, y_train, X_vote, seed=args.seed, device=config.DEVICE, sample_weight=train_sample_weight,
                hidden=mlp_hidden, epochs=mlp_epochs, lr=mlp_lr, weight_decay=mlp_weight_decay
            )

        if vote_score == "mean_proba":
            score = mean_proba
        elif vote_score == "stacked":
            score = stacked_proba
        elif vote_score == "mlp":
            score = mlp_proba
        else:
            score = vote_sum.astype(np.float32)

        if vote_score in ["mean_proba", "stacked", "mlp"]:
            y_vote_hard = (score >= prob_threshold).astype(int)
        else:
            y_vote_hard = (vote_sum >= args.vote_k).astype(int)

        # vote_rule:
        # - hard:  å¯¹æ‰€æœ‰ idx_vote éƒ½ç”¨ç¡¬é˜ˆå€¼è¦†ç›–
        # - band:  ä»…åœ¨ä½ç¥¨/é«˜ç¥¨æ—¶è¦†ç›–ï¼Œå…¶ä½™ä¿ç•™HCï¼ˆé¿å…æŠŠä¸ç¡®å®šæ ·æœ¬æ”¹åï¼‰
        # - none:  ä¸è¦†ç›–ï¼ˆç­‰ä»·äºåªç”¨HCç»“æœï¼‰
        vote_rule = getattr(args, "vote_rule", "hard")
        band_low = int(getattr(args, "band_low", -1))
        band_high = int(getattr(args, "band_high", len(model_names) + 1))

        if vote_rule == "none":
            vote_apply_local = np.zeros((len(idx_vote),), dtype=bool)
            y_vote_final = y_corrected[idx_vote].astype(int)
        elif vote_rule == "band":
            if vote_score in ["mean_proba", "stacked", "mlp"]:
                vote_apply_local = (score <= prob_low) | (score >= prob_high)
                y_vote_final = y_corrected[idx_vote].astype(int).copy()
                y_vote_final[score <= prob_low] = 0
                y_vote_final[score >= prob_high] = 1
            else:
                vote_apply_local = (vote_sum <= band_low) | (vote_sum >= band_high)
                y_vote_final = y_corrected[idx_vote].astype(int).copy()
                y_vote_final[vote_sum <= band_low] = 0
                y_vote_final[vote_sum >= band_high] = 1
        else:
            vote_apply_local = np.ones((len(idx_vote),), dtype=bool)
            y_vote_final = y_vote_hard

        vote_distribution = [0] * (len(model_names) + 1)
        for v in vote_sum:
            vote_distribution[int(v)] += 1
        
        model_malicious_ratio = {}
        for i, name in enumerate(model_names):
            model_malicious_ratio[name] = float(vote_mat[:, i].mean()) if vote_mat.size else 0.0
        
        # y_final: ä»¥ HybridCourt çš„ y_corrected ä¸ºåº•åº§ï¼Œåªåœ¨ vote_rule æŒ‡å®šçš„å­é›†åšè¦†ç›–
        y_pred_all = y_corrected.copy()
        y_pred_all[idx_vote[vote_apply_local]] = y_vote_final[vote_apply_local]

        metrics_vote = calculate_metrics(y_true[idx_vote], y_pred_all[idx_vote]) if len(idx_vote) > 0 else None
        report_vote = classification_report(y_true[idx_vote], y_pred_all[idx_vote], digits=4, zero_division=0) if len(idx_vote) > 0 else ""

    metrics_all = calculate_metrics(y_true, y_pred_all)
    correction_accuracy = float(metrics_all.get("accuracy", 0.0))

    # baseline å¯¹æ¯”ï¼šnoisy / HC / final
    acc_noisy = float(np.mean(y_noisy == y_true))
    acc_hc = float(np.mean(y_corrected == y_true))

    sample_report_path = os.path.join(args.output_dir, "sample_analysis.csv")
    vote_sum_all = np.full((len(y_true),), -1, dtype=np.int32)
    vote_pred_all = np.full((len(y_true),), -1, dtype=np.int32)
    vote_sum_all[idx_vote] = vote_sum.astype(np.int32)
    vote_pred_all[idx_vote] = y_vote_final.astype(np.int32)

    vote_score_value_all = np.full((len(y_true),), -1.0, dtype=np.float32)
    if len(idx_vote) > 0:
        vote_score_value_all[idx_vote] = score.astype(np.float32)

    vote_applied_all = np.zeros((len(y_true),), dtype=np.uint8)
    if len(idx_vote) > 0:
        vote_applied_all[idx_vote[vote_apply_local]] = 1

    model_vote_all = {}
    for mi, name in enumerate(model_names):
        arr = np.full((len(y_true),), -1, dtype=np.int32)
        if vote_mat.size:
            arr[idx_vote] = vote_mat[:, mi].astype(np.int32)
        model_vote_all[name] = arr

    with open(sample_report_path, "w", encoding="utf-8", newline="") as fcsv:
        fieldnames = [
            "index",
            "y_true",
            "y_noisy",
            "y_corrected_hc",
            "y_final",
            "noise_injected",
            "action_mask",
            "correction_weight",
            "keep_mask",
            "vote_applied",
            "vote_sum",
            "vote_pred",
            "vote_score_value",
        ] + [f"vote_{n}" for n in model_names]
        wcsv = csv.DictWriter(fcsv, fieldnames=fieldnames)
        wcsv.writeheader()
        for i in range(len(y_true)):
            row = {
                "index": int(i),
                "y_true": int(y_true[i]),
                "y_noisy": int(y_noisy[i]),
                "y_corrected_hc": int(y_corrected[i]),
                "y_final": int(y_pred_all[i]),
                "noise_injected": int(bool(noise_mask[i])),
                "action_mask": int(action_mask[i]),
                "correction_weight": float(correction_weight[i]),
                "keep_mask": int(bool(keep_mask[i])),
                "vote_applied": int(vote_applied_all[i]),
                "vote_sum": int(vote_sum_all[i]),
                "vote_pred": int(vote_pred_all[i]),
                "vote_score_value": float(vote_score_value_all[i]),
            }
            for n in model_names:
                row[f"vote_{n}"] = int(model_vote_all[n][i])
            wcsv.writerow(row)
    
    results = {
        "mode": "from_preprocessed",
        "data_split": str(args.data_split),
        "noise_rate": float(args.noise_rate),
        "train_on": str(args.train_on),
        "features_source": features_source,
        "n_total": int(len(y_true)),
        "n_keep": int(len(idx_keep)),
        "n_rest": int(len(idx_rest)),
        "n_vote": int(len(idx_vote)),
        "n_vote_applied": int(vote_applied_all.sum()),
        "vote_rule": str(vote_rule),
        "band_low": int(band_low),
        "band_high": int(band_high),
        "vote_score": str(vote_score),
        "prob_threshold": float(prob_threshold),
        "prob_low": float(prob_low),
        "prob_high": float(prob_high),
        "true_benign": int((y_true == 0).sum()),
        "true_malicious": int((y_true == 1).sum()),
        "noise_injected": int(noise_mask.sum()),
        "action_keep": int((action_mask == 0).sum()),
        "action_flip": int((action_mask == 1).sum()),
        "action_drop": int((action_mask == 2).sum()),
        "action_reweight": int((action_mask == 3).sum()),
        "correction_weight": correction_weight,
        "train_samples": int(len(X_train)),
        "models": list(fitted.keys()),
        "model_accuracies": accuracies,
        "vote_distribution": vote_distribution,
        "model_malicious_ratio": model_malicious_ratio,
        "metrics_vote": metrics_vote,
        "metrics_all": metrics_all,
        "correction_accuracy": correction_accuracy,
        "report_vote": report_vote,
        "acc_noisy": acc_noisy,
        "acc_hc": acc_hc,
        "sample_report": sample_report_path,
    }
    
    if not getattr(args, 'skip_plots', False):
        fig_dir = os.path.join(args.output_dir, "figures")
        plot_quality_distribution(
            correction_weight, y_true, idx_keep, idx_rest,
            os.path.join(fig_dir, "1_è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png"), logger
        )
        
        plot_vote_analysis(
            vote_mat, vote_sum, y_pred_all[idx_vote].astype(int), idx_vote, y_corrected, model_names,
            os.path.join(fig_dir, "2_æŠ•ç¥¨åˆ†æ.png"), logger
        )
        
        plot_feature_space(
            features, y_true, y_pred_all, idx_keep, idx_rest,
            os.path.join(fig_dir, "3_ç‰¹å¾ç©ºé—´å¯è§†åŒ–.png"), logger
        )
    logger.info("")
    
    logger.info("æ­¥éª¤7: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    logger.info("-"*70)
    generate_report(args, results, os.path.join(args.output_dir, "report.txt"), logger)
    logger.info("")
    
    logger.info("æ­¥éª¤8: ä¿å­˜æ•°æ®æ–‡ä»¶")
    logger.info("-"*70)
    summary = {
        "mode": "from_preprocessed",
        "data_split": str(args.data_split),
        "noise_rate": float(args.noise_rate),
        "train_on": str(args.train_on),
        "n_total": int(len(y_true)),
        "n_keep": int(len(idx_keep)),
        "n_rest": int(len(idx_rest)),
        "n_vote": int(len(idx_vote)),
        "n_vote_applied": int(vote_applied_all.sum()),
        "vote_rule": str(vote_rule),
        "band_low": int(band_low),
        "band_high": int(band_high),
        "vote_score": str(vote_score),
        "prob_threshold": float(prob_threshold),
        "prob_low": float(prob_low),
        "prob_high": float(prob_high),
        "vote_k": int(args.vote_k),
        "eval_all": _to_jsonable(metrics_all),
        "eval_vote": _to_jsonable(metrics_vote),
        "correction_accuracy": correction_accuracy,
        "acc_noisy": acc_noisy,
        "acc_hc": acc_hc,
        "sample_report": sample_report_path,
    }
    with open(os.path.join(args.output_dir, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    logger.info("  âœ“ summary.json")
    
    np.save(os.path.join(args.output_dir, "y_true.npy"), y_true)
    np.save(os.path.join(args.output_dir, "y_noisy.npy"), y_noisy)
    np.save(os.path.join(args.output_dir, "y_corrected_hc.npy"), y_corrected)
    np.save(os.path.join(args.output_dir, "action_mask.npy"), action_mask.astype(np.int32))
    np.save(os.path.join(args.output_dir, "y_pred_all.npy"), y_pred_all)
    np.save(os.path.join(args.output_dir, "features.npy"), features.astype(np.float32))
    np.save(os.path.join(args.output_dir, "idx_keep.npy"), idx_keep.astype(np.int64))
    np.save(os.path.join(args.output_dir, "idx_rest.npy"), idx_rest.astype(np.int64))
    np.save(os.path.join(args.output_dir, "keep_mask.npy"), keep_mask.astype(np.uint8))
    np.save(os.path.join(args.output_dir, "correction_weight.npy"), correction_weight)
    logger.info("  âœ“ y_true.npy, y_noisy.npy, y_corrected_hc.npy, y_pred_all.npy")
    logger.info("  âœ“ idx_keep.npy, idx_rest.npy, keep_mask.npy, correction_weight.npy")
    logger.info("")
    
    logger.info("="*70)
    logger.info("ğŸ‰ å®éªŒå®Œæˆ! (from_preprocessed)")
    logger.info("="*70)
    logger.info("")
    logger.info("ğŸ“Š ç»“æœæ‘˜è¦:")
    logger.info(f"  baseline(noisy) acc={acc_noisy:.4f} | HC acc={acc_hc:.4f} | final acc={correction_accuracy:.4f}")
    logger.info(f"  eval_all:  acc={metrics_all['accuracy']:.4f}, f1(pos=1)={metrics_all['f1_pos']:.4f}")
    logger.info(f"  Correction accuracy: {correction_accuracy:.4f}")
    if metrics_vote is not None:
        logger.info(f"  eval_vote: acc={metrics_vote['accuracy']:.4f}, f1(pos=1)={metrics_vote['f1_pos']:.4f}")
    logger.info(f"  è¾“å‡ºç›®å½•: {args.output_dir}")
    logger.info(f"  æ ·æœ¬åˆ†æCSV: {sample_report_path}")


def _fit_models(models: dict, X_train: np.ndarray, y_train: np.ndarray, logger, sample_weight=None):
    """è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
    fitted = {}
    accuracies = {}
    
    for name, model in models.items():
        logger.info(f"  è®­ç»ƒ {name}...")
        _fit_estimator(model, X_train, y_train, sample_weight=sample_weight)
        fitted[name] = model
        
        # è®¡ç®—è®­ç»ƒé›†å‡†ç¡®ç‡
        train_pred = model.predict(X_train)
        acc = (train_pred == y_train).mean()
        accuracies[name] = acc
        logger.info(f"    âœ“ {name} è®­ç»ƒå®Œæˆï¼Œè®­ç»ƒé›†å‡†ç¡®ç‡: {acc*100:.2f}%")
    
    return fitted, accuracies


def _vote_predict(fitted: dict, X: np.ndarray) -> tuple:
    """å¯¹æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨é¢„æµ‹"""
    votes = []
    names = list(fitted.keys())
    
    for name, model in fitted.items():
        pred = model.predict(X)
        votes.append(pred.astype(int))
    
    vote_mat = np.stack(votes, axis=1) if votes else np.zeros((len(X), 0), dtype=int)
    return vote_mat, names


def plot_quality_distribution(quality, y_base, idx_high, idx_low, save_path, logger):
    """ç»˜åˆ¶è´¨é‡åˆ†æ•°åˆ†å¸ƒå›¾"""
    logger.info("ç»˜åˆ¶è´¨é‡åˆ†æ•°åˆ†å¸ƒå›¾...")
    
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # 1. æ•´ä½“è´¨é‡åˆ†æ•°åˆ†å¸ƒ
    ax = axes[0]
    ax.hist(quality[y_base == 0], bins=50, alpha=0.6, label='æ­£å¸¸æµé‡', color='#2E86AB')
    ax.hist(quality[y_base == 1], bins=50, alpha=0.6, label='æ¶æ„æµé‡', color='#A23B72')
    ax.axvline(np.percentile(quality, 50), color='red', linestyle='--', label='ä¸­ä½æ•°')
    ax.set_xlabel('è´¨é‡åˆ†æ•°')
    ax.set_ylabel('æ ·æœ¬æ•°é‡')
    ax.set_title('æ ·æœ¬è´¨é‡åˆ†æ•°åˆ†å¸ƒ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. é«˜/ä½è´¨é‡æ ·æœ¬åˆ†å¸ƒ
    ax = axes[1]
    high_q = quality[idx_high]
    low_q = quality[idx_low]
    ax.hist(high_q, bins=30, alpha=0.6, label=f'é«˜è´¨é‡ (n={len(idx_high)})', color='#06A77D')
    ax.hist(low_q, bins=30, alpha=0.6, label=f'ä½è´¨é‡ (n={len(idx_low)})', color='#D62828')
    ax.set_xlabel('è´¨é‡åˆ†æ•°')
    ax.set_ylabel('æ ·æœ¬æ•°é‡')
    ax.set_title('é«˜/ä½è´¨é‡æ ·æœ¬åˆ†å¸ƒ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. è´¨é‡åˆ†æ•°ç®±çº¿å›¾
    ax = axes[2]
    data = [quality[y_base == 0], quality[y_base == 1]]
    bp = ax.boxplot(data, labels=['æ­£å¸¸æµé‡', 'æ¶æ„æµé‡'], patch_artist=True)
    bp['boxes'][0].set_facecolor('#2E86AB')
    bp['boxes'][1].set_facecolor('#A23B72')
    ax.set_ylabel('è´¨é‡åˆ†æ•°')
    ax.set_title('å„ç±»åˆ«è´¨é‡åˆ†æ•°ç®±çº¿å›¾')
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    logger.info(f"  âœ“ å·²ä¿å­˜: {save_path}")


def plot_vote_analysis(vote_mat, vote_sum, y_low_pred, idx_low, y_base, model_names, save_path, logger):
    """ç»˜åˆ¶æŠ•ç¥¨åˆ†æå›¾"""
    logger.info("ç»˜åˆ¶æŠ•ç¥¨åˆ†æå›¾...")
    
    fig, axes = plt.subplots(2, 2, figsize=(14, 12))
    
    # 1. æŠ•ç¥¨åˆ†å¸ƒç›´æ–¹å›¾
    ax = axes[0, 0]
    ax.hist(vote_sum, bins=range(len(model_names)+2), alpha=0.7, color='#2E86AB', edgecolor='black')
    ax.set_xlabel('æŠ•ç¥¨æ•°ï¼ˆåˆ¤ä¸ºæ¶æ„çš„æ¨¡å‹æ•°ï¼‰')
    ax.set_ylabel('æ ·æœ¬æ•°é‡')
    ax.set_title('ä½è´¨é‡æ ·æœ¬æŠ•ç¥¨åˆ†å¸ƒ')
    ax.set_xticks(range(len(model_names)+1))
    ax.grid(True, alpha=0.3)
    
    # 2. å„æ¨¡å‹é¢„æµ‹åˆ†å¸ƒ
    ax = axes[0, 1]
    model_preds = vote_mat.sum(axis=0) / len(vote_mat) * 100
    bars = ax.bar(model_names, model_preds, color='#06A77D', edgecolor='black')
    ax.set_xlabel('æ¨¡å‹')
    ax.set_ylabel('é¢„æµ‹ä¸ºæ¶æ„çš„æ¯”ä¾‹ (%)')
    ax.set_title('å„æ¨¡å‹å¯¹ä½è´¨é‡æ ·æœ¬çš„é¢„æµ‹')
    ax.set_xticklabels(model_names, rotation=45, ha='right')
    ax.grid(True, alpha=0.3)
    for bar, val in zip(bars, model_preds):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, f'{val:.1f}%', 
                ha='center', va='bottom', fontsize=9)
    
    # 3. æ¨¡å‹ä¸€è‡´æ€§çƒ­åŠ›å›¾
    ax = axes[1, 0]
    agreement = np.corrcoef(vote_mat.T)
    sns.heatmap(agreement, annot=True, fmt='.2f', cmap='RdYlGn', 
                xticklabels=model_names, yticklabels=model_names, ax=ax)
    ax.set_title('æ¨¡å‹é¢„æµ‹ä¸€è‡´æ€§ (ç›¸å…³ç³»æ•°)')
    
    # 4. çŸ«æ­£å‰åå¯¹æ¯”
    ax = axes[1, 1]
    original_labels = y_base[idx_low]
    categories = ['ä¿æŒæ­£å¸¸', 'æ­£å¸¸â†’æ¶æ„', 'æ¶æ„â†’æ­£å¸¸', 'ä¿æŒæ¶æ„']
    counts = [
        ((original_labels == 0) & (y_low_pred == 0)).sum(),
        ((original_labels == 0) & (y_low_pred == 1)).sum(),
        ((original_labels == 1) & (y_low_pred == 0)).sum(),
        ((original_labels == 1) & (y_low_pred == 1)).sum()
    ]
    colors = ['#2E86AB', '#F77F00', '#D62828', '#A23B72']
    bars = ax.bar(categories, counts, color=colors, edgecolor='black')
    ax.set_ylabel('æ ·æœ¬æ•°é‡')
    ax.set_title('ä½è´¨é‡æ ·æœ¬çŸ«æ­£ç»“æœ')
    ax.set_xticklabels(categories, rotation=15, ha='right')
    ax.grid(True, alpha=0.3)
    for bar, val in zip(bars, counts):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, str(val), 
                ha='center', va='bottom', fontsize=10, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    logger.info(f"  âœ“ å·²ä¿å­˜: {save_path}")


def plot_feature_space(features, y_base, y_final, idx_high, idx_low, save_path, logger):
    """ç»˜åˆ¶ç‰¹å¾ç©ºé—´å¯è§†åŒ–"""
    logger.info("ç»˜åˆ¶ç‰¹å¾ç©ºé—´å¯è§†åŒ– (t-SNE)...")
    logger.info("  æ­£åœ¨è¿›è¡Œt-SNEé™ç»´ï¼Œè¯·ç¨å€™...")
    
    # t-SNEé™ç»´
    tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)
    features_2d = tsne.fit_transform(features)
    
    fig, axes = plt.subplots(1, 3, figsize=(18, 6))
    
    # 1. åŸå§‹æ ‡ç­¾åˆ†å¸ƒ
    ax = axes[0]
    ax.scatter(features_2d[y_base == 0, 0], features_2d[y_base == 0, 1],
               c='#2E86AB', label='æ­£å¸¸æµé‡', alpha=0.5, s=20)
    ax.scatter(features_2d[y_base == 1, 0], features_2d[y_base == 1, 1],
               c='#A23B72', label='æ¶æ„æµé‡', alpha=0.5, s=20)
    ax.set_xlabel('t-SNE ç»´åº¦1')
    ax.set_ylabel('t-SNE ç»´åº¦2')
    ax.set_title('åŸå§‹æ ‡ç­¾åˆ†å¸ƒ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 2. é«˜/ä½è´¨é‡æ ·æœ¬åˆ†å¸ƒ
    ax = axes[1]
    ax.scatter(features_2d[idx_high, 0], features_2d[idx_high, 1],
               c='#06A77D', label=f'é«˜è´¨é‡ (n={len(idx_high)})', alpha=0.5, s=20)
    ax.scatter(features_2d[idx_low, 0], features_2d[idx_low, 1],
               c='#D62828', label=f'ä½è´¨é‡ (n={len(idx_low)})', alpha=0.5, s=20)
    ax.set_xlabel('t-SNE ç»´åº¦1')
    ax.set_ylabel('t-SNE ç»´åº¦2')
    ax.set_title('é«˜/ä½è´¨é‡æ ·æœ¬åˆ†å¸ƒ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    # 3. çŸ«æ­£åæ ‡ç­¾åˆ†å¸ƒ
    ax = axes[2]
    ax.scatter(features_2d[y_final == 0, 0], features_2d[y_final == 0, 1],
               c='#2E86AB', label='æ­£å¸¸æµé‡', alpha=0.5, s=20)
    ax.scatter(features_2d[y_final == 1, 0], features_2d[y_final == 1, 1],
               c='#A23B72', label='æ¶æ„æµé‡', alpha=0.5, s=20)
    # æ ‡è®°è¢«çŸ«æ­£çš„æ ·æœ¬
    changed_mask = y_base != y_final
    if changed_mask.sum() > 0:
        ax.scatter(features_2d[changed_mask, 0], features_2d[changed_mask, 1],
                   facecolors='none', edgecolors='lime', s=100, linewidths=2,
                   label=f'å·²çŸ«æ­£ (n={changed_mask.sum()})')
    ax.set_xlabel('t-SNE ç»´åº¦1')
    ax.set_ylabel('t-SNE ç»´åº¦2')
    ax.set_title('MLæŠ•ç¥¨çŸ«æ­£åæ ‡ç­¾åˆ†å¸ƒ')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    logger.info(f"  âœ“ å·²ä¿å­˜: {save_path}")


def generate_report(args, results, save_path, logger):
    """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
    logger.info("ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
    
    with open(save_path, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("MLæŠ•ç¥¨æ ‡ç­¾çŸ«æ­£å®éªŒ - è¯¦ç»†åˆ†ææŠ¥å‘Š\n")
        f.write("="*80 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("\n")

        if getattr(args, 'mode', 'legacy') == 'from_preprocessed':
            f.write("-"*80 + "\n")
            f.write("1. å®éªŒé…ç½®\n")
            f.write("-"*80 + "\n")
            f.write(f"  æ¨¡å¼:           {results.get('mode', 'from_preprocessed')}\n")
            f.write(f"  æ•°æ®åˆ‡åˆ†:       {results.get('data_split', '')}\n")
            f.write(f"  æ³¨å…¥å™ªå£°ç‡:     {results.get('noise_rate', 0.0):.2f}\n")
            f.write(f"  è®­ç»ƒé›†å£å¾„:     {results.get('train_on', 'keep')}\n")
            f.write(f"  ç‰¹å¾æ¥æº:       {results.get('features_source', '')}\n")
            f.write(f"  æŠ•ç¥¨é˜ˆå€¼:       {args.vote_k} (è‡³å°‘{args.vote_k}ä¸ªæ¨¡å‹åŒæ„æ‰åˆ¤ä¸ºæ¶æ„)\n")
            f.write(f"  ç±»åˆ«å¹³è¡¡è®­ç»ƒ:   {'æ˜¯' if args.balance_train else 'å¦'}\n")
            f.write(f"  éšæœºç§å­:       {args.seed}\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("2. æ•°æ®ç»Ÿè®¡\n")
            f.write("-"*80 + "\n")
            f.write(f"  æ€»æ ·æœ¬æ•°:       {results['n_total']}\n")
            f.write(f"  Keepæ ·æœ¬(è®­ç»ƒ): {results['n_keep']} ({100*results['n_keep']/results['n_total']:.1f}%)\n")
            f.write(f"  å…¶ä½™æ ·æœ¬(éè®­ç»ƒ): {results['n_rest']} ({100*results['n_rest']/results['n_total']:.1f}%)\n")
            f.write(f"  æŠ•ç¥¨çŸ«æ­£æ ·æœ¬(Reweight): {results.get('n_vote', 0)} ({100*results.get('n_vote', 0)/results['n_total']:.1f}%)\n")
            if 'n_vote_applied' in results:
                f.write(f"  å®é™…è¦†ç›–æ ·æœ¬:   {results.get('n_vote_applied', 0)}\n")
            if 'vote_rule' in results:
                f.write(f"  æŠ•ç¥¨è§„åˆ™:       {results.get('vote_rule', '')} (band_low={results.get('band_low', '')}, band_high={results.get('band_high', '')})\n")
            if 'vote_score' in results:
                f.write(f"  æŠ•ç¥¨æ‰“åˆ†:       {results.get('vote_score', '')} (prob_th={results.get('prob_threshold', '')}, prob_low={results.get('prob_low', '')}, prob_high={results.get('prob_high', '')})\n")
            f.write(f"  çœŸå®æ ‡ç­¾åˆ†å¸ƒ:   æ­£å¸¸={results.get('true_benign', 0)}, æ¶æ„={results.get('true_malicious', 0)}\n")
            f.write(f"  æ³¨å…¥å™ªå£°æ ·æœ¬:   {results.get('noise_injected', 0)}\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("3. HybridCourt åŠ¨ä½œç»Ÿè®¡\n")
            f.write("-"*80 + "\n")
            f.write(f"  Keep:           {results.get('action_keep', 0)}\n")
            f.write(f"  Flip:           {results.get('action_flip', 0)}\n")
            f.write(f"  Drop:           {results.get('action_drop', 0)}\n")
            f.write(f"  Reweight:       {results.get('action_reweight', 0)}\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("4. æ¨¡å‹è®­ç»ƒç»“æœ\n")
            f.write("-"*80 + "\n")
            f.write(f"  è®­ç»ƒæ ·æœ¬æ•°:     {results.get('train_samples', 0)}\n")
            f.write(f"  ä½¿ç”¨çš„æ¨¡å‹:     {len(results.get('models', []))} ä¸ª\n")
            f.write("\n")
            f.write(f"  {'æ¨¡å‹åç§°':<20} {'è®­ç»ƒé›†å‡†ç¡®ç‡':>15}\n")
            f.write(f"  {'-'*20} {'-'*15}\n")
            for name, acc in results.get('model_accuracies', {}).items():
                f.write(f"  {name:<20} {acc*100:>14.2f}%\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("5. æŠ•ç¥¨é¢„æµ‹ç»“æœ\n")
            f.write("-"*80 + "\n")
            f.write(f"  å¾…é¢„æµ‹æ ·æœ¬æ•°(Reweight):   {results.get('n_vote', 0)}\n")
            f.write(f"  æŠ•ç¥¨é˜ˆå€¼:       {args.vote_k}\n")
            f.write("\n")
            f.write("  æŠ•ç¥¨åˆ†å¸ƒ:\n")
            for i, count in enumerate(results.get('vote_distribution', [])):
                f.write(f"    {i}ç¥¨åˆ¤æ¶æ„:   {count} ä¸ªæ ·æœ¬\n")
            f.write("\n")
            f.write("  å„æ¨¡å‹é¢„æµ‹ä¸ºæ¶æ„çš„æ¯”ä¾‹:\n")
            for name, ratio in results.get('model_malicious_ratio', {}).items():
                f.write(f"    {name:<20} {ratio*100:>6.2f}%\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("6. è¯„ä¼° (é¢„æµ‹ vs çœŸå®æ ‡ç­¾)\n")
            f.write("-"*80 + "\n")
            f.write("  Baselineå¯¹æ¯”:\n")
            f.write(f"    y_noisy vs y_true:        {results.get('acc_noisy', 0.0):.4f}\n")
            f.write(f"    y_corrected_hc vs y_true: {results.get('acc_hc', 0.0):.4f}\n")
            f.write(f"    y_final vs y_true:        {results.get('correction_accuracy', 0.0):.4f}\n")
            f.write("\n")
            m_all = results.get('metrics_all', {})
            f.write("  å…¨é‡è¯„ä¼°:\n")
            f.write(f"    Accuracy:     {m_all.get('accuracy', 0.0):.4f}\n")
            f.write(f"    F1(pos=1):    {m_all.get('f1_pos', 0.0):.4f}\n")
            f.write(f"    Correction accuracy: {results.get('correction_accuracy', m_all.get('accuracy', 0.0)):.4f}\n")
            f.write(f"    Confusion:\n{m_all.get('confusion_matrix', '')}\n")
            f.write("\n")
            m_vote = results.get('metrics_vote', None)
            if m_vote is not None:
                f.write("  ä»…å¯¹æŠ•ç¥¨çŸ«æ­£æ ·æœ¬(Reweight)è¯„ä¼°:\n")
                f.write(f"    Accuracy:     {m_vote.get('accuracy', 0.0):.4f}\n")
                f.write(f"    F1(pos=1):    {m_vote.get('f1_pos', 0.0):.4f}\n")
                f.write(f"    Confusion:\n{m_vote.get('confusion_matrix', '')}\n")
                if results.get('report_vote', ''):
                    f.write("\n")
                    f.write("  Classification Report (vote/reweight):\n")
                    f.write(results.get('report_vote', '') + "\n")
            f.write("\n")

            f.write("-"*80 + "\n")
            f.write("7. è¾“å‡ºæ–‡ä»¶\n")
            f.write("-"*80 + "\n")
            f.write(f"  åˆ†ææŠ¥å‘Š:       {save_path}\n")
            f.write(f"  å®éªŒæ‘˜è¦:       {args.output_dir}/summary.json\n")
            if results.get('sample_report', ''):
                f.write(f"  æ ·æœ¬åˆ†æCSV:    {results.get('sample_report', '')}\n")
            f.write(f"  è´¨é‡åˆ†å¸ƒå›¾:     {args.output_dir}/figures/1_è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png\n")
            f.write(f"  æŠ•ç¥¨åˆ†æå›¾:     {args.output_dir}/figures/2_æŠ•ç¥¨åˆ†æ.png\n")
            f.write(f"  ç‰¹å¾ç©ºé—´å›¾:     {args.output_dir}/figures/3_ç‰¹å¾ç©ºé—´å¯è§†åŒ–.png\n")
            f.write(f"  æ ‡ç­¾æ–‡ä»¶:       {args.output_dir}/y_true.npy, y_noisy.npy, y_corrected_hc.npy, y_pred_all.npy\n")
            f.write("\n")
            f.write("="*80 + "\n")
            return
        
        # å®éªŒé…ç½®
        f.write("-"*80 + "\n")
        f.write("1. å®éªŒé…ç½®\n")
        f.write("-"*80 + "\n")
        f.write(f"  ç‰¹å¾æ–‡ä»¶:       {args.features}\n")
        f.write(f"  çŸ«æ­£ç»“æœæ–‡ä»¶:   {args.correction}\n")
        f.write(f"  é«˜è´¨é‡æ ·æœ¬æ¯”ä¾‹: {args.hq_ratio} (legacyæ¨¡å¼ä¸‹å·²ä¸ä½œä¸ºåˆ’åˆ†ä¾æ®)\n")
        f.write(f"  è®­ç»ƒé›†å£å¾„:     {getattr(args, 'train_on', 'keep')}\n")
        f.write(f"  æŠ•ç¥¨é˜ˆå€¼:       {args.vote_k} (è‡³å°‘{args.vote_k}ä¸ªæ¨¡å‹åŒæ„æ‰åˆ¤ä¸ºæ¶æ„)\n")
        f.write(f"  åŸºç¡€æ ‡ç­¾:       {args.use_base}\n")
        f.write(f"  ç±»åˆ«å¹³è¡¡è®­ç»ƒ:   {'æ˜¯' if args.balance_train else 'å¦'}\n")
        f.write(f"  éšæœºç§å­:       {args.seed}\n")
        f.write("\n")
        
        # æ•°æ®ç»Ÿè®¡
        f.write("-"*80 + "\n")
        f.write("2. æ•°æ®ç»Ÿè®¡\n")
        f.write("-"*80 + "\n")
        f.write(f"  æ€»æ ·æœ¬æ•°:       {results['n_total']}\n")
        f.write(f"  é«˜è´¨é‡æ ·æœ¬:     {results['n_high']} ({100*results['n_high']/results['n_total']:.1f}%)\n")
        f.write(f"  ä½è´¨é‡æ ·æœ¬:     {results['n_low']} ({100*results['n_low']/results['n_total']:.1f}%)\n")
        f.write(f"  Dropæ ·æœ¬:       {results.get('n_drop', 0)} ({100*results.get('n_drop', 0)/results['n_total']:.1f}%)\n")
        f.write("\n")
        f.write(f"  åŸå§‹æ ‡ç­¾åˆ†å¸ƒ:\n")
        f.write(f"    æ­£å¸¸æµé‡:     {results['original_benign']}\n")
        f.write(f"    æ¶æ„æµé‡:     {results['original_malicious']}\n")
        f.write("\n")

        f.write("-"*80 + "\n")
        f.write("3. æ ‡ç­¾çŸ«æ­£åŠ¨ä½œç»Ÿè®¡ (HybridCourt)\n")
        f.write("-"*80 + "\n")
        f.write(f"  Keep:           {results.get('action_keep', 0)}\n")
        f.write(f"  Flip:           {results.get('action_flip', 0)}\n")
        f.write(f"  Drop:           {results.get('action_drop', 0)}\n")
        f.write(f"  Reweight:       {results.get('action_reweight', 0)}\n")
        f.write("\n")
        
        # è´¨é‡åˆ†æ•°ç»Ÿè®¡
        f.write("-"*80 + "\n")
        f.write("4. è´¨é‡åˆ†æ•°ç»Ÿè®¡\n")
        f.write("-"*80 + "\n")
        q = results['quality']
        f.write(f"  æœ€å°å€¼:         {q.min():.4f}\n")
        f.write(f"  æœ€å¤§å€¼:         {q.max():.4f}\n")
        f.write(f"  å‡å€¼:           {q.mean():.4f}\n")
        f.write(f"  ä¸­ä½æ•°:         {np.median(q):.4f}\n")
        f.write(f"  æ ‡å‡†å·®:         {q.std():.4f}\n")
        f.write("\n")
        f.write(f"  é«˜è´¨é‡æ ·æœ¬è´¨é‡åˆ†æ•°: {results.get('high_quality_mean', 0.0):.4f} Â± {results.get('high_quality_std', 0.0):.4f}\n")
        f.write(f"  ä½è´¨é‡æ ·æœ¬è´¨é‡åˆ†æ•°: {results.get('low_quality_mean', 0.0):.4f} Â± {results.get('low_quality_std', 0.0):.4f}\n")
        f.write("\n")
        
        # æ¨¡å‹è®­ç»ƒç»“æœ
        f.write("-"*80 + "\n")
        f.write("5. æ¨¡å‹è®­ç»ƒç»“æœ\n")
        f.write("-"*80 + "\n")
        f.write(f"  è®­ç»ƒæ ·æœ¬æ•°:     {results.get('train_samples', 0)}\n")
        f.write(f"  ä½¿ç”¨çš„æ¨¡å‹:     {len(results.get('models', []))} ä¸ª\n")
        f.write("\n")
        f.write(f"  {'æ¨¡å‹åç§°':<20} {'è®­ç»ƒé›†å‡†ç¡®ç‡':>15}\n")
        f.write(f"  {'-'*20} {'-'*15}\n")
        for name, acc in results['model_accuracies'].items():
            f.write(f"  {name:<20} {acc*100:>14.2f}%\n")
        f.write("\n")
        
        # æŠ•ç¥¨ç»“æœ
        f.write("-"*80 + "\n")
        f.write("6. æŠ•ç¥¨çŸ«æ­£ç»“æœ\n")
        f.write("-"*80 + "\n")
        f.write(f"  ä½è´¨é‡æ ·æœ¬æ•°:   {results['n_low']}\n")
        f.write(f"  æŠ•ç¥¨é˜ˆå€¼:       {args.vote_k}\n")
        f.write("\n")
        f.write(f"  æŠ•ç¥¨åˆ†å¸ƒ:\n")
        for i, count in enumerate(results['vote_distribution']):
            f.write(f"    {i}ç¥¨åˆ¤æ¶æ„:   {count} ä¸ªæ ·æœ¬\n")
        f.write("\n")
        f.write(f"  å„æ¨¡å‹é¢„æµ‹ä¸ºæ¶æ„çš„æ¯”ä¾‹:\n")
        for name, ratio in results['model_malicious_ratio'].items():
            f.write(f"    {name:<20} {ratio*100:>6.2f}%\n")
        f.write("\n")
        
        # çŸ«æ­£ç»Ÿè®¡
        f.write("-"*80 + "\n")
        f.write("7. çŸ«æ­£ç»Ÿè®¡\n")
        f.write("-"*80 + "\n")
        f.write(f"  æ ‡ç­¾å˜åŒ–æ•°:     {results['changed']} ({100*results['changed']/results['n_total']:.2f}%)\n")
        f.write("\n")
        f.write(f"  ä½è´¨é‡æ ·æœ¬çŸ«æ­£è¯¦æƒ…:\n")
        f.write(f"    ä¿æŒæ­£å¸¸:     {results['keep_benign']}\n")
        f.write(f"    æ­£å¸¸â†’æ¶æ„:    {results['benign_to_malicious']}\n")
        f.write(f"    æ¶æ„â†’æ­£å¸¸:    {results['malicious_to_benign']}\n")
        f.write(f"    ä¿æŒæ¶æ„:     {results['keep_malicious']}\n")
        f.write("\n")
        f.write(f"  çŸ«æ­£åæ ‡ç­¾åˆ†å¸ƒ:\n")
        f.write(f"    æ­£å¸¸æµé‡:     {results['final_benign']}\n")
        f.write(f"    æ¶æ„æµé‡:     {results['final_malicious']}\n")
        f.write("\n")

        # çŸ«æ­£ååˆ†æï¼ˆä¼˜å…ˆä½¿ç”¨y_trueï¼›è‹¥æ— y_trueåˆ™å›é€€åˆ°ä¸HCè¾“å‡ºçš„ä¸€è‡´ç‡ï¼‰
        f.write("-"*80 + "\n")
        f.write("8. çŸ«æ­£ååˆ†æ(ä¸€è‡´ç‡/æ··æ·†çŸ©é˜µ)\n")
        f.write("-"*80 + "\n")
        if results.get('has_y_true', False):
            f.write("  âœ… å·²åŠ è½½çœŸå®æ ‡ç­¾(y_true)ï¼Œä»¥ä¸‹ä¸ºçœŸå®è¯„ä¼°æŒ‡æ ‡(é¢„æµ‹ vs çœŸå®)ï¼š\n")
            f.write(f"  Correction accuracy: {results.get('correction_accuracy', results.get('acc_true', 0.0)):.4f}\n")
            f.write(f"  Accuracy:        {results.get('acc_true', 0.0):.4f}\n")
            f.write(f"  F1(pos=1):       {results.get('f1_true', 0.0):.4f}\n")
            if results.get('cm_true', ''):
                f.write(f"  Confusion Matrix (y_true vs y_final):\n{results.get('cm_true', '')}\n")
            f.write("\n")

            # è¯¦ç»†å­é›†è¯„ä¼°
            f.write("  å­é›†è¯„ä¼°(Accuracy/F1)ï¼š\n")
            for key, title in [
                ('metrics_all', 'All'),
                ('metrics_train', 'TrainSubset'),
                ('metrics_vote', 'VoteSubset'),
                ('metrics_changed', 'ChangedOnly'),
                ('metrics_keep', 'Action=Keep'),
                ('metrics_flip', 'Action=Flip'),
                ('metrics_reweight', 'Action=Reweight'),
                ('metrics_drop', 'Action=Drop'),
            ]:
                m = results.get(key, None)
                if isinstance(m, dict):
                    f.write(f"    {title:<14} acc={m.get('accuracy', 0.0):.4f}, f1(pos=1)={m.get('f1_pos', 0.0):.4f}\n")
            f.write("\n")

        f.write("  å‚è€ƒä¸€è‡´ç‡(ç”¨äºå¯¹é½HybridCourtè¾“å‡º/è¾“å…¥æ ‡ç­¾)ï¼š\n")
        f.write(f"    ä¸ y_corrected(HC) ä¸€è‡´ç‡: {results.get('acc_vs_hc', 0.0):.4f}\n")
        f.write(f"    ä¸ y_noisy ä¸€è‡´ç‡:         {results.get('acc_vs_noisy', 0.0):.4f}\n")
        f.write(f"    ä¸ y_base ä¸€è‡´ç‡:          {results.get('acc_vs_base', 0.0):.4f}\n")
        if results.get('cm_vs_hc', ''):
            f.write(f"    Confusion Matrix (y_corrected vs y_final):\n{results.get('cm_vs_hc', '')}\n")
        f.write("\n")
        
        # è¾“å‡ºæ–‡ä»¶
        f.write("-"*80 + "\n")
        f.write("9. è¾“å‡ºæ–‡ä»¶\n")
        f.write("-"*80 + "\n")
        f.write(f"  åˆ†ææŠ¥å‘Š:       {save_path}\n")
        f.write(f"  å®éªŒæ‘˜è¦:       {args.output_dir}/summary.json\n")
        f.write(f"  è´¨é‡åˆ†å¸ƒå›¾:     {args.output_dir}/figures/1_è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png\n")
        f.write(f"  æŠ•ç¥¨åˆ†æå›¾:     {args.output_dir}/figures/2_æŠ•ç¥¨åˆ†æ.png\n")
        f.write(f"  ç‰¹å¾ç©ºé—´å›¾:     {args.output_dir}/figures/3_ç‰¹å¾ç©ºé—´å¯è§†åŒ–.png\n")
        f.write(f"  çŸ«æ­£åæ ‡ç­¾:     {args.output_dir}/y_corrected_ml.npy\n")
        if results.get('sample_report', ''):
            f.write(f"  æ ·æœ¬åˆ†æCSV:    {results.get('sample_report', '')}\n")
        f.write("\n")
        f.write("="*80 + "\n")
    
    logger.info(f"  âœ“ å·²ä¿å­˜: {save_path}")


def main():
    ap = argparse.ArgumentParser(description="MLæŠ•ç¥¨æ ‡ç­¾çŸ«æ­£å®éªŒ")
    ap.add_argument("--mode", type=str, default="legacy", choices=["legacy", "from_preprocessed"], help="è¿è¡Œæ¨¡å¼")
    ap.add_argument("--data_split", type=str, default="train", choices=["train", "test"], help="é¢„å¤„ç†æ•°æ®åˆ‡åˆ†")
    ap.add_argument("--noise_rate", type=float, default=0.0, help="æ³¨å…¥æ ‡ç­¾å™ªå£°ç‡(ç”¨äºå¯æ§è¯„ä¼°)ï¼Œ0è¡¨ç¤ºä¸æ³¨å…¥")
    ap.add_argument("--features_npy", type=str, default="", help="(å¯é€‰) ç›´æ¥æä¾›(N,d)ç‰¹å¾npyï¼Œè·³è¿‡backboneç‰¹å¾æå–")
    ap.add_argument("--backbone", type=str, default="", help="(å¯é€‰) backboneæƒé‡è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨output/feature_extraction/models/backbone_pretrained.pth")
    ap.add_argument("--hc_impl", type=str, default="experimental", choices=["experimental", "original"], help="HybridCourtå®ç°é€‰æ‹©: experimental=å¤åˆ¶ç‰ˆ(å¯ä¿®æ”¹), original=åŸç‰ˆ(ä¸æ”¹åŠ¨)")
    ap.add_argument("--skip_plots", action="store_true", help="è·³è¿‡ç»˜å›¾ä¸t-SNEï¼ˆç”¨äºè‡ªåŠ¨è°ƒå‚åŠ é€Ÿï¼‰")
    ap.add_argument("--save_cache_dir", type=str, default="", help="(å¯é€‰) ä¿å­˜from_preprocessedé˜¶æ®µçš„features/HCè¾“å‡ºåˆ°ç¼“å­˜ç›®å½•ï¼ˆç”¨äºè‡ªåŠ¨è°ƒå‚å¤ç”¨ï¼‰")
    ap.add_argument("--reuse_cache_dir", type=str, default="", help="(å¯é€‰) å¤ç”¨ç¼“å­˜ç›®å½•ï¼Œè·³è¿‡ç‰¹å¾æå–ä¸HybridCourt")
    ap.add_argument("--train_on", type=str, default="keep", choices=["keep", "keep_flip", "nondrop"], help="è®­ç»ƒé›†å£å¾„: keep=action==0, keep_flip=action in {0,1}, nondrop=action!=2")
    ap.add_argument("--features", type=str, default="./output/feature_extraction/models/train_features.npy")
    ap.add_argument("--correction", type=str, default="./output/label_correction/models/correction_results.npz")
    ap.add_argument("--output_dir", type=str, default="./experiments/ml_vote_label_correction/output")
    ap.add_argument("--hq_ratio", type=float, default=0.5, help="é«˜è´¨é‡æ ·æœ¬æ¯”ä¾‹")
    ap.add_argument("--balance_train", action="store_true", help="å¯ç”¨ç±»åˆ«å¹³è¡¡è®­ç»ƒ")
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--use_base", type=str, default="y_corrected", choices=["y_corrected", "y_noisy"])
    ap.add_argument("--vote_k", type=int, default=4, help="æŠ•ç¥¨é˜ˆå€¼")
    ap.add_argument("--vote_rule", type=str, default="hard", choices=["hard", "band", "none"], help="æŠ•ç¥¨è¦†ç›–ç­–ç•¥: hard=å…¨è¦†ç›–, band=é«˜ç½®ä¿¡è¦†ç›–, none=ä¸è¦†ç›–")
    ap.add_argument("--band_low", type=int, default=-1, help="bandç­–ç•¥: vote_sum<=band_low åˆ¤ä¸ºæ­£å¸¸å¹¶è¦†ç›–")
    ap.add_argument("--band_high", type=int, default=8, help="bandç­–ç•¥: vote_sum>=band_high åˆ¤ä¸ºæ¶æ„å¹¶è¦†ç›–")
    ap.add_argument("--vote_include_drop", action="store_true", help="å…è®¸å¯¹Drop(action=2)æ ·æœ¬ä¹Ÿè¿›è¡ŒæŠ•ç¥¨/æ¦‚ç‡é«˜ç½®ä¿¡è¦†ç›–")
    ap.add_argument("--flip_train_weight", type=float, default=0.5, help="train_on=keep_flipæ—¶ï¼Œå¯¹Flip(action=1)æ ·æœ¬çš„è®­ç»ƒæƒé‡é¢å¤–ä¹˜ä»¥è¯¥ç³»æ•°")
    ap.add_argument("--vote_score", type=str, default="count", choices=["count", "mean_proba", "stacked", "mlp"], help="æŠ•ç¥¨æ‰“åˆ†æ–¹å¼: count=ç¥¨æ•°, mean_proba=å¹³å‡æ¦‚ç‡, stacked=stackingæ¦‚ç‡, mlp=MLPæ¦‚ç‡")
    ap.add_argument("--prob_threshold", type=float, default=0.5, help="æ¦‚ç‡ç¡¬è¦†ç›–é˜ˆå€¼(score>=thåˆ¤æ¶æ„)ï¼Œä»…å¯¹vote_score!=countç”Ÿæ•ˆ")
    ap.add_argument("--prob_low", type=float, default=0.3, help="bandç­–ç•¥(æ¦‚ç‡): score<=prob_low åˆ¤æ­£å¸¸å¹¶è¦†ç›–")
    ap.add_argument("--prob_high", type=float, default=0.7, help="bandç­–ç•¥(æ¦‚ç‡): score>=prob_high åˆ¤æ¶æ„å¹¶è¦†ç›–")
    ap.add_argument("--mlp_hidden", type=int, default=128, help="MLP hidden size (vote_score=mlp)")
    ap.add_argument("--mlp_epochs", type=int, default=200, help="MLP epochs (vote_score=mlp)")
    ap.add_argument("--mlp_lr", type=float, default=1e-3, help="MLP learning rate (vote_score=mlp)")
    ap.add_argument("--mlp_weight_decay", type=float, default=1e-4, help="MLP weight decay (vote_score=mlp)")
    args = ap.parse_args()

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    os.makedirs(os.path.join(args.output_dir, "figures"), exist_ok=True)

    logger.info("="*70)
    logger.info("MLæŠ•ç¥¨æ ‡ç­¾çŸ«æ­£å®éªŒ")
    logger.info("="*70)
    logger.info(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("")

    if args.mode == "from_preprocessed":
        logger.info("æ­¥éª¤1: åŠ è½½é¢„å¤„ç†æ•°æ®")
        logger.info("-"*70)
        _run_from_preprocessed(args, logger)
        return

    # åŠ è½½æ•°æ®
    logger.info("æ­¥éª¤1: åŠ è½½æ•°æ®")
    logger.info("-"*70)
    
    if not os.path.exists(args.features):
        logger.error(f"âŒ ç‰¹å¾æ–‡ä»¶ä¸å­˜åœ¨: {args.features}")
        return
    if not os.path.exists(args.correction):
        logger.error(f"âŒ çŸ«æ­£ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {args.correction}")
        return

    features = np.load(args.features)
    corr = np.load(args.correction, allow_pickle=True)
    
    logger.info(f"  ç‰¹å¾å½¢çŠ¶: {features.shape}")

    required = ["y_noisy", "y_corrected", "correction_weight", "density_scores", "neighbor_consistency", "pred_probs"]
    missing = [k for k in required if k not in corr]
    if missing:
        logger.error(f"âŒ ç¼ºå°‘å¿…è¦å­—æ®µ: {missing}")
        return

    y_noisy = corr["y_noisy"].astype(int)
    y_corrected = corr["y_corrected"].astype(int)
    y_base = y_corrected if args.use_base == "y_corrected" else y_noisy

    # å°è¯•åŠ è½½çœŸå®æ ‡ç­¾(y_true)ï¼šå‚è€ƒlabel_correction_analysisï¼Œé€šè¿‡é¢„å¤„ç†æ•°æ®è·å–
    y_true = None
    if PREPROCESS_AVAILABLE and check_preprocessed_exists('train'):
        try:
            _, y_tmp, _ = load_preprocessed('train')
            y_tmp = y_tmp.astype(int)
            if len(y_tmp) == len(y_base):
                y_true = y_tmp
            else:
                # å¦‚æœtrainä¸åŒ¹é…ï¼Œå†å°è¯•test
                if check_preprocessed_exists('test'):
                    _, y_tmp2, _ = load_preprocessed('test')
                    y_tmp2 = y_tmp2.astype(int)
                    if len(y_tmp2) == len(y_base):
                        y_true = y_tmp2
        except Exception:
            y_true = None

    w = corr["correction_weight"].astype(np.float32)
    density = corr["density_scores"].astype(np.float32)
    knn_cons = corr["neighbor_consistency"].astype(np.float32)
    cl_conf = _softmax_max_prob(corr["pred_probs"]).astype(np.float32)

    logger.info(f"  æ€»æ ·æœ¬æ•°: {len(y_base)}")
    logger.info(f"  æ­£å¸¸æµé‡: {(y_base == 0).sum()}")
    logger.info(f"  æ¶æ„æµé‡: {(y_base == 1).sum()}")
    logger.info("")

    # è®¡ç®—è´¨é‡åˆ†æ•°
    logger.info("æ­¥éª¤2: è®¡ç®—è´¨é‡åˆ†æ•°")
    logger.info("-"*70)
    
    density_norm = _minmax01(density)
    knn_cons = np.clip(knn_cons, 0.0, 1.0)
    cl_conf = np.clip(cl_conf, 0.0, 1.0)
    w = np.clip(w, 0.0, None)

    quality = (0.5 * density_norm + 0.5 * knn_cons) * cl_conf
    quality = quality * np.maximum(w, 1e-6)
    
    logger.info(f"  è´¨é‡åˆ†æ•°èŒƒå›´: [{quality.min():.4f}, {quality.max():.4f}]")
    logger.info(f"  è´¨é‡åˆ†æ•°å‡å€¼: {quality.mean():.4f}")
    logger.info("")

    # ä½¿ç”¨æ ‡ç­¾çŸ«æ­£æ¨¡å—äº§ç‰©(action_mask)åˆç­›é«˜/ä½è´¨é‡æ•°æ®é›†
    logger.info("æ­¥éª¤3: åŸºäºæ ‡ç­¾çŸ«æ­£åŠ¨ä½œåˆ’åˆ†é«˜/ä½è´¨é‡æ•°æ®é›†")
    logger.info("-"*70)

    if "action_mask" not in corr:
        logger.error("âŒ correction_results.npz ç¼ºå°‘ action_maskï¼Œæ— æ³•æŒ‰æ ‡ç­¾çŸ«æ­£åˆç­›æ•°æ®ã€‚")
        return

    rng = np.random.default_rng(args.seed)
    action_mask = corr["action_mask"].astype(int)

    # action çº¦å®š: 0=Keep, 1=Flip, 2=Drop, 3=Reweight
    idx_keep = np.where(action_mask == 0)[0]
    idx_flip = np.where(action_mask == 1)[0]
    idx_drop = np.where(action_mask == 2)[0]
    idx_reweight = np.where(action_mask == 3)[0]

    if args.train_on == "keep":
        train_mask = action_mask == 0
    else:
        train_mask = action_mask != 2

    idx_high = np.where(train_mask)[0]
    # ä½è´¨é‡é›†åˆï¼šä¸è¿›å…¥è®­ç»ƒé›†ä¸”édrop(é»˜è®¤ä¸å¯¹dropæŠ•ç¥¨)
    idx_low = np.where((~train_mask) & (action_mask != 2))[0]

    logger.info(f"  train_on: {args.train_on}")
    logger.info(f"  Keep:     {len(idx_keep)}")
    logger.info(f"  Flip:     {len(idx_flip)}")
    logger.info(f"  Drop:     {len(idx_drop)}")
    logger.info(f"  Reweight: {len(idx_reweight)}")
    logger.info(f"  é«˜è´¨é‡(è®­ç»ƒ)æ ·æœ¬: {len(idx_high)} ({100*len(idx_high)/len(y_base):.1f}%)")
    logger.info(f"  ä½è´¨é‡(æŠ•ç¥¨)æ ·æœ¬: {len(idx_low)} ({100*len(idx_low)/len(y_base):.1f}%)")
    logger.info("")

    if len(idx_high) == 0:
        logger.error("âŒ é«˜è´¨é‡è®­ç»ƒé›†ä¸ºç©ºï¼ˆæŒ‰action_maskç­›é€‰ï¼‰ã€‚è¯·æ£€æŸ¥æ ‡ç­¾çŸ«æ­£ç»“æœæˆ–å°è¯• --train_on nondrop")
        return

    # å‡†å¤‡è®­ç»ƒæ•°æ®
    X_train = features[idx_high]
    y_train = y_base[idx_high]

    if args.balance_train:
        logger.info("  å¯ç”¨ç±»åˆ«å¹³è¡¡è®­ç»ƒ...")
        idx0 = idx_high[y_base[idx_high] == 0]
        idx1 = idx_high[y_base[idx_high] == 1]
        n = min(len(idx0), len(idx1))
        if n > 0:
            idx0_s = rng.choice(idx0, size=n, replace=False)
            idx1_s = rng.choice(idx1, size=n, replace=False)
            idx_bal = np.concatenate([idx0_s, idx1_s])
            rng.shuffle(idx_bal)
            X_train = features[idx_bal]
            y_train = y_base[idx_bal]
            logger.info(f"  å¹³è¡¡åè®­ç»ƒæ ·æœ¬: {len(X_train)} (æ¯ç±» {n})")

    # è®­ç»ƒæ¨¡å‹
    logger.info("")
    logger.info("æ­¥éª¤4: è®­ç»ƒMLæ¨¡å‹")
    logger.info("-"*70)
    
    models = _build_models(args.seed)
    logger.info(f"  ä½¿ç”¨ {len(models)} ä¸ªæ¨¡å‹: {list(models.keys())}")
    logger.info("")
    
    fitted, accuracies = _fit_models(models, X_train, y_train, logger)
    logger.info("")

    # å¯¹ä½è´¨é‡æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨
    logger.info("æ­¥éª¤5: å¯¹ä½è´¨é‡æ ·æœ¬è¿›è¡ŒæŠ•ç¥¨çŸ«æ­£")
    logger.info("-"*70)
    
    X_low = features[idx_low]
    vote_mat, model_names = _vote_predict(fitted, X_low)
    vote_sum = vote_mat.sum(axis=1) if vote_mat.size else np.zeros((len(X_low),), dtype=int)
    y_low_pred = (vote_sum >= args.vote_k).astype(int)

    # ç»Ÿè®¡æŠ•ç¥¨åˆ†å¸ƒ
    vote_distribution = [0] * (len(model_names) + 1)
    for v in vote_sum:
        vote_distribution[v] += 1
    
    logger.info(f"  æŠ•ç¥¨é˜ˆå€¼: {args.vote_k}")
    logger.info(f"  æŠ•ç¥¨åˆ†å¸ƒ:")
    for i, count in enumerate(vote_distribution):
        logger.info(f"    {i}ç¥¨åˆ¤æ¶æ„: {count} ä¸ªæ ·æœ¬")
    logger.info("")

    # ç”Ÿæˆæœ€ç»ˆæ ‡ç­¾
    y_final = y_base.copy()
    y_final[idx_low] = y_low_pred

    # legacyæ¨¡å¼çš„â€œçŸ«æ­£ååˆ†æâ€ï¼šç”±äºç¼ºå°‘y_trueï¼Œè®¡ç®—ä¸HC/å™ªå£°/åŸºç¡€æ ‡ç­¾çš„ä¸€è‡´ç‡
    acc_vs_hc = float(np.mean(y_final == y_corrected))
    acc_vs_noisy = float(np.mean(y_final == y_noisy))
    acc_vs_base = float(np.mean(y_final == y_base))
    cm_vs_hc = confusion_matrix(y_corrected, y_final, labels=[0, 1])
    cm_vs_hc_str = np.array2string(cm_vs_hc)

    has_y_true = y_true is not None
    acc_true = None
    f1_true = None
    cm_true_str = ""
    metrics_all = None
    metrics_train = None
    metrics_vote = None
    metrics_changed = None
    metrics_keep = None
    metrics_flip = None
    metrics_reweight = None
    metrics_drop = None
    if has_y_true:
        # å…¨é‡æŒ‡æ ‡
        metrics_all = calculate_metrics(y_true, y_final)
        acc_true = float(metrics_all.get('accuracy', 0.0))
        f1_true = float(metrics_all.get('f1_pos', 0.0))
        cm_true = confusion_matrix(y_true, y_final, labels=[0, 1])
        cm_true_str = np.array2string(cm_true)

        # å­é›†æŒ‡æ ‡
        if len(idx_high) > 0:
            metrics_train = calculate_metrics(y_true[idx_high], y_final[idx_high])
        if len(idx_low) > 0:
            metrics_vote = calculate_metrics(y_true[idx_low], y_final[idx_low])
        changed_idx = np.where(y_final != y_base)[0]
        if len(changed_idx) > 0:
            metrics_changed = calculate_metrics(y_true[changed_idx], y_final[changed_idx])
        if len(idx_keep) > 0:
            metrics_keep = calculate_metrics(y_true[idx_keep], y_final[idx_keep])
        if len(idx_flip) > 0:
            metrics_flip = calculate_metrics(y_true[idx_flip], y_final[idx_flip])
        if len(idx_reweight) > 0:
            metrics_reweight = calculate_metrics(y_true[idx_reweight], y_final[idx_reweight])
        if len(idx_drop) > 0:
            metrics_drop = calculate_metrics(y_true[idx_drop], y_final[idx_drop])

    # ç»Ÿè®¡å˜åŒ–
    changed = int(np.sum(y_final != y_base))
    original_low = y_base[idx_low]
    keep_benign = ((original_low == 0) & (y_low_pred == 0)).sum()
    benign_to_malicious = ((original_low == 0) & (y_low_pred == 1)).sum()
    malicious_to_benign = ((original_low == 1) & (y_low_pred == 0)).sum()
    keep_malicious = ((original_low == 1) & (y_low_pred == 1)).sum()

    logger.info(f"  æ ‡ç­¾å˜åŒ–ç»Ÿè®¡:")
    logger.info(f"    ä¿æŒæ­£å¸¸:     {keep_benign}")
    logger.info(f"    æ­£å¸¸â†’æ¶æ„:    {benign_to_malicious}")
    logger.info(f"    æ¶æ„â†’æ­£å¸¸:    {malicious_to_benign}")
    logger.info(f"    ä¿æŒæ¶æ„:     {keep_malicious}")
    logger.info(f"    æ€»å˜åŒ–æ•°:     {changed} ({100*changed/len(y_base):.2f}%)")
    logger.info("")

    # æ”¶é›†ç»“æœ
    model_malicious_ratio = {}
    for i, name in enumerate(model_names):
        model_malicious_ratio[name] = vote_mat[:, i].mean()

    results = {
        'n_total': len(y_base),
        'n_high': len(idx_high),
        'n_low': len(idx_low),
        'n_drop': int(len(idx_drop)),
        'train_on': str(args.train_on),
        'action_keep': int(len(idx_keep)),
        'action_flip': int(len(idx_flip)),
        'action_drop': int(len(idx_drop)),
        'action_reweight': int(len(idx_reweight)),
        'original_benign': int((y_base == 0).sum()),
        'original_malicious': int((y_base == 1).sum()),
        'final_benign': int((y_final == 0).sum()),
        'final_malicious': int((y_final == 1).sum()),
        'quality': quality,
        'high_quality_mean': float(quality[idx_high].mean()),
        'high_quality_std': float(quality[idx_high].std()),
        'low_quality_mean': float(quality[idx_low].mean()) if len(idx_low) > 0 else 0,
        'low_quality_std': float(quality[idx_low].std()) if len(idx_low) > 0 else 0,
        'train_samples': len(X_train),
        'models': list(fitted.keys()),
        'model_accuracies': accuracies,
        'vote_distribution': vote_distribution,
        'model_malicious_ratio': model_malicious_ratio,
        'changed': changed,
        'keep_benign': int(keep_benign),
        'benign_to_malicious': int(benign_to_malicious),
        'malicious_to_benign': int(malicious_to_benign),
        'keep_malicious': int(keep_malicious),
        'acc_vs_hc': acc_vs_hc,
        'acc_vs_noisy': acc_vs_noisy,
        'acc_vs_base': acc_vs_base,
        'cm_vs_hc': cm_vs_hc_str,
        'has_y_true': bool(has_y_true),
        'acc_true': float(acc_true) if acc_true is not None else 0.0,
        'f1_true': float(f1_true) if f1_true is not None else 0.0,
        'correction_accuracy': float(acc_true) if acc_true is not None else 0.0,
        'cm_true': cm_true_str,
        'metrics_all': metrics_all,
        'metrics_train': metrics_train,
        'metrics_vote': metrics_vote,
        'metrics_changed': metrics_changed,
        'metrics_keep': metrics_keep,
        'metrics_flip': metrics_flip,
        'metrics_reweight': metrics_reweight,
        'metrics_drop': metrics_drop,
    }

    # é€æ ·æœ¬åˆ†ææŠ¥å‘Šï¼ˆCSVï¼‰
    sample_report_path = os.path.join(args.output_dir, "sample_analysis.csv")
    vote_sum_all = np.full((len(y_base),), -1, dtype=np.int32)
    vote_pred_all = np.full((len(y_base),), -1, dtype=np.int32)
    vote_sum_all[idx_low] = vote_sum.astype(np.int32)
    vote_pred_all[idx_low] = y_low_pred.astype(np.int32)

    model_vote_all = {}
    for mi, name in enumerate(model_names):
        arr = np.full((len(y_base),), -1, dtype=np.int32)
        if vote_mat.size:
            arr[idx_low] = vote_mat[:, mi].astype(np.int32)
        model_vote_all[name] = arr

    in_train = np.zeros((len(y_base),), dtype=np.int32)
    in_vote = np.zeros((len(y_base),), dtype=np.int32)
    in_train[idx_high] = 1
    in_vote[idx_low] = 1

    with open(sample_report_path, "w", encoding="utf-8", newline="") as fcsv:
        fieldnames = [
            "index",
            "y_true",
            "y_noisy",
            "y_corrected_hc",
            "y_base",
            "y_final",
            "action_mask",
            "correction_weight",
            "density_score",
            "knn_consistency",
            "cl_conf",
            "quality",
            "in_train",
            "in_vote",
            "vote_sum",
            "vote_pred",
        ] + [f"vote_{n}" for n in model_names]
        wcsv = csv.DictWriter(fcsv, fieldnames=fieldnames)
        wcsv.writeheader()
        for i in range(len(y_base)):
            row = {
                "index": int(i),
                "y_true": int(y_true[i]) if has_y_true else -1,
                "y_noisy": int(y_noisy[i]),
                "y_corrected_hc": int(y_corrected[i]),
                "y_base": int(y_base[i]),
                "y_final": int(y_final[i]),
                "action_mask": int(action_mask[i]),
                "correction_weight": float(w[i]),
                "density_score": float(density[i]),
                "knn_consistency": float(knn_cons[i]),
                "cl_conf": float(cl_conf[i]),
                "quality": float(quality[i]),
                "in_train": int(in_train[i]),
                "in_vote": int(in_vote[i]),
                "vote_sum": int(vote_sum_all[i]),
                "vote_pred": int(vote_pred_all[i]),
            }
            for n in model_names:
                row[f"vote_{n}"] = int(model_vote_all[n][i])
            wcsv.writerow(row)

    results["sample_report"] = sample_report_path

    # ç”Ÿæˆå¯è§†åŒ–
    logger.info("æ­¥éª¤6: ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    logger.info("-"*70)
    
    fig_dir = os.path.join(args.output_dir, "figures")
    
    plot_quality_distribution(
        quality, y_base, idx_high, idx_low,
        os.path.join(fig_dir, "1_è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png"), logger
    )
    
    plot_vote_analysis(
        vote_mat, vote_sum, y_low_pred, idx_low, y_base, model_names,
        os.path.join(fig_dir, "2_æŠ•ç¥¨åˆ†æ.png"), logger
    )
    
    plot_feature_space(
        features, y_base, y_final, idx_high, idx_low,
        os.path.join(fig_dir, "3_ç‰¹å¾ç©ºé—´å¯è§†åŒ–.png"), logger
    )
    logger.info("")

    # ç”ŸæˆæŠ¥å‘Š
    logger.info("æ­¥éª¤7: ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    logger.info("-"*70)
    
    generate_report(args, results, os.path.join(args.output_dir, "report.txt"), logger)
    logger.info("")

    # ä¿å­˜æ•°æ®æ–‡ä»¶
    logger.info("æ­¥éª¤8: ä¿å­˜æ•°æ®æ–‡ä»¶")
    logger.info("-"*70)

    # ä¿å­˜æ‘˜è¦JSON
    summary = {
        "n_total": int(len(y_base)),
        "n_high": int(len(idx_high)),
        "n_low": int(len(idx_low)),
        "n_drop": int(len(idx_drop)),
        "hq_ratio": float(args.hq_ratio),
        "train_on": str(args.train_on),
        "balance_train": bool(args.balance_train),
        "vote_k": int(args.vote_k),
        "changed": changed,
        "base_label": args.use_base,
        "models": list(fitted.keys()),
        "original_benign": int((y_base == 0).sum()),
        "original_malicious": int((y_base == 1).sum()),
        "final_benign": int((y_final == 0).sum()),
        "final_malicious": int((y_final == 1).sum()),
        "acc_vs_hc": float(acc_vs_hc),
        "acc_vs_noisy": float(acc_vs_noisy),
        "acc_vs_base": float(acc_vs_base),
        "has_y_true": bool(has_y_true),
        "acc_true": float(acc_true) if acc_true is not None else None,
        "f1_true": float(f1_true) if f1_true is not None else None,
        "correction_accuracy": float(acc_true) if acc_true is not None else None,
    }

    with open(os.path.join(args.output_dir, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    logger.info(f"  âœ“ summary.json")

    np.save(os.path.join(args.output_dir, "y_base.npy"), y_base)
    np.save(os.path.join(args.output_dir, "y_corrected_ml.npy"), y_final)
    np.save(os.path.join(args.output_dir, "quality_score.npy"), quality)
    logger.info(f"  âœ“ y_base.npy, y_corrected_ml.npy, quality_score.npy")
    logger.info("")

    # æœ€ç»ˆæ€»ç»“
    logger.info("="*70)
    logger.info("ğŸ‰ å®éªŒå®Œæˆ!")
    logger.info("="*70)
    logger.info("")
    logger.info("ğŸ“Š ç»“æœæ‘˜è¦:")
    logger.info(f"  æ€»æ ·æœ¬æ•°:       {len(y_base)}")
    logger.info(f"  é«˜è´¨é‡æ ·æœ¬:     {len(idx_high)} ({100*len(idx_high)/len(y_base):.1f}%)")
    logger.info(f"  ä½è´¨é‡æ ·æœ¬:     {len(idx_low)} ({100*len(idx_low)/len(y_base):.1f}%)")
    logger.info(f"  æ ‡ç­¾å˜åŒ–æ•°:     {changed} ({100*changed/len(y_base):.2f}%)")
    if has_y_true:
        logger.info(f"  Correction accuracy: {acc_true:.4f}")
    logger.info("")
    logger.info(f"  åŸå§‹åˆ†å¸ƒ:       æ­£å¸¸={results['original_benign']}, æ¶æ„={results['original_malicious']}")
    logger.info(f"  çŸ«æ­£ååˆ†å¸ƒ:     æ­£å¸¸={results['final_benign']}, æ¶æ„={results['final_malicious']}")
    logger.info("")
    logger.info("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
    logger.info(f"  {args.output_dir}/report.txt")
    logger.info(f"  {args.output_dir}/figures/1_è´¨é‡åˆ†æ•°åˆ†å¸ƒ.png")
    logger.info(f"  {args.output_dir}/figures/2_æŠ•ç¥¨åˆ†æ.png")
    logger.info(f"  {args.output_dir}/figures/3_ç‰¹å¾ç©ºé—´å¯è§†åŒ–.png")
    logger.info("="*70)


if __name__ == "__main__":
    main()
