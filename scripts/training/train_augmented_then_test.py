"""
MEDAL-Lite æ•°æ®å¢å¼ºè®­ç»ƒ+æµ‹è¯•è„šæœ¬ (é‡æ„ç‰ˆ)
=========================================
ä½¿ç”¨çœŸå®æ ‡ç­¾ + TabDDPMæ•°æ®å¢å¼ºè®­ç»ƒåˆ†ç±»å™¨ï¼Œå¤ç”¨ä¸»æµç¨‹ä»£ç 
"""
import os
import sys
from pathlib import Path

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

import json
import argparse
from datetime import datetime
import hashlib
import random

import numpy as np
import torch
from torch.utils.data import TensorDataset, DataLoader

from MoudleCode.utils.config import config
from MoudleCode.utils.helpers import set_seed, setup_logger
from MoudleCode.utils.logging_utils import (
    log_section_header, log_data_stats, log_input_paths, log_output_paths, log_final_summary
)
from MoudleCode.preprocessing.pcap_parser import load_dataset
from MoudleCode.feature_extraction.backbone import build_backbone

try:
    from scripts.utils.preprocess import check_preprocessed_exists, load_preprocessed, normalize_burstsize_inplace
    PREPROCESS_AVAILABLE = True
except Exception:
    PREPROCESS_AVAILABLE = False

from scripts.training.train import stage1_pretrain_backbone, stage2_label_correction_and_augmentation, stage3_finetune_classifier
from scripts.testing.test import main as test_main


def _safe_makedirs(path: str) -> None:
    os.makedirs(path, exist_ok=True)


def _rng_fingerprint_short() -> str:
    h = hashlib.sha256()
    try:
        h.update(repr(random.getstate()).encode('utf-8'))
    except Exception:
        h.update(b'py_random_error')
    try:
        ns = np.random.get_state()
        h.update(str(ns[0]).encode('utf-8'))
        h.update(np.asarray(ns[1], dtype=np.uint32).tobytes())
        h.update(str(ns[2]).encode('utf-8'))
        h.update(str(ns[3]).encode('utf-8'))
        h.update(str(ns[4]).encode('utf-8'))
    except Exception:
        h.update(b'numpy_random_error')
    try:
        h.update(torch.get_rng_state().detach().cpu().numpy().tobytes())
    except Exception:
        h.update(b'torch_cpu_rng_error')
    try:
        if torch.cuda.is_available():
            for s in torch.cuda.get_rng_state_all():
                h.update(s.detach().cpu().numpy().tobytes())
        else:
            h.update(b'no_cuda')
    except Exception:
        h.update(b'torch_cuda_rng_error')
    return h.hexdigest()[:16]


def _seed_snapshot(args_seed: int) -> str:
    torch_seed = None
    try:
        torch_seed = int(torch.initial_seed())
    except Exception:
        torch_seed = None
    return (
        f"args.seed={int(args_seed)} | "
        f"config.SEED={int(getattr(config, 'SEED', -1))} | "
        f"torch.initial_seed={torch_seed}"
    )


def _advance_rng_to_stage2_baseline(logger, args_seed: int) -> None:
    """Align RNG state to match the non-retrain pipeline right before Stage2.

    In the non-retrain run, RNG typically advances due to backbone initialization.
    We reproduce that consumption by building a throwaway backbone once.
    """
    logger.info(f"ğŸ”§ RNGå¯¹é½(Stage2åŸºçº¿) - èµ·ç‚¹: {_rng_fingerprint_short()} ({_seed_snapshot(args_seed)})")
    _tmp = build_backbone(config, logger=logger)
    del _tmp
    logger.info(f"ğŸ”§ RNGå¯¹é½(Stage2åŸºçº¿) - é‡æ”¾å: {_rng_fingerprint_short()} ({_seed_snapshot(args_seed)})")


def _load_train_dataset():
    """åŠ è½½è®­ç»ƒæ•°æ®é›†"""
    if PREPROCESS_AVAILABLE and check_preprocessed_exists('train'):
        X_train, y_train, _ = load_preprocessed('train')
        X_train = normalize_burstsize_inplace(X_train)
        return X_train, y_train

    X_train, y_train, _ = load_dataset(
        benign_dir=config.BENIGN_TRAIN,
        malicious_dir=config.MALICIOUS_TRAIN,
        sequence_length=config.SEQUENCE_LENGTH,
    )
    X_train = normalize_burstsize_inplace(X_train)
    return X_train, y_train


def main():
    parser = argparse.ArgumentParser(description="æ•°æ®å¢å¼ºè®­ç»ƒ+æµ‹è¯•")
    parser.add_argument('--retrain_backbone', action='store_true', help='é‡æ–°è®­ç»ƒéª¨å¹²ç½‘ç»œ')
    parser.add_argument('--backbone_path', type=str, default='', help='éª¨å¹²ç½‘ç»œè·¯å¾„')
    parser.add_argument('--seed', type=int, default=42)
    parser.add_argument('--run_tag', type=str, default='')
    args = parser.parse_args()

    rng_fp_before_seed = _rng_fingerprint_short()
    set_seed(args.seed)
    rng_fp_after_seed = _rng_fingerprint_short()
    config.create_dirs()
    logger = setup_logger(os.path.join(config.OUTPUT_ROOT, 'logs'), name='augmented_train_test')

    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå‰): {rng_fp_before_seed}")
    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå): {rng_fp_after_seed} ({_seed_snapshot(args.seed)})")

    # é…ç½®ï¼šä½¿ç”¨æœ€ä¼˜å‚æ•°
    config.USE_FOCAL_LOSS = True
    config.USE_BCE_LOSS = False
    config.USE_SOFT_F1_LOSS = False
    config.STAGE3_ONLINE_AUGMENTATION = False
    config.STAGE3_USE_ST_MIXUP = False
    config.FINETUNE_BACKBONE = False  # ç‰¹å¾ç©ºé—´æ•°æ®ä¸æ”¯æŒéª¨å¹²å¾®è°ƒ
    config.FINETUNE_VAL_SPLIT = 0.0
    config.FINETUNE_ES_ALLOW_TRAIN_METRIC = True

    run_tag = args.run_tag.strip() or datetime.now().strftime('%Y%m%d_%H%M%S')
    run_dir = os.path.join(config.LABEL_CORRECTION_DIR, 'analysis', 'augmented_runs', run_tag)
    _safe_makedirs(run_dir)
    
    # éš”ç¦»è¾“å‡ºç›®å½•
    original_classification_dir = config.CLASSIFICATION_DIR
    original_result_dir = config.RESULT_DIR
    original_data_aug_dir = config.DATA_AUGMENTATION_DIR
    
    config.CLASSIFICATION_DIR = os.path.join(run_dir, 'classification')
    config.RESULT_DIR = os.path.join(run_dir, 'result')
    config.DATA_AUGMENTATION_DIR = os.path.join(run_dir, 'data_augmentation')
    
    for d in [config.CLASSIFICATION_DIR, config.RESULT_DIR, config.DATA_AUGMENTATION_DIR]:
        _safe_makedirs(d)
        _safe_makedirs(os.path.join(d, 'models'))
        _safe_makedirs(os.path.join(d, 'figures'))
        _safe_makedirs(os.path.join(d, 'logs'))

    try:
        log_section_header(logger, "ğŸš€ æ•°æ®å¢å¼ºè®­ç»ƒ+æµ‹è¯•æ¨¡å¼ï¼ˆæ¶ˆèå®éªŒï¼‰")
        logger.info(f'è¿è¡Œç›®å½•: {run_dir}')
        logger.info(f'æ—¶é—´æˆ³: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}')
        logger.info('')
        logger.info('ğŸ“‹ è®­ç»ƒæ¨¡å¼è¯´æ˜:')
        logger.info('  - æ•°æ®æ¥æº: åŸå§‹æ•°æ® + TabDDPMå¢å¼ºæ•°æ®')
        logger.info('  - æ ‡ç­¾: çœŸå®æ ‡ç­¾ï¼ˆæ— å™ªå£°ï¼‰')
        logger.info('  - æ ‡ç­¾çŸ«æ­£: è·³è¿‡ï¼ˆä½¿ç”¨çœŸå®æ ‡ç­¾ï¼‰')
        logger.info('  - æ•°æ®å¢å¼º: TabDDPMï¼ˆç‰¹å¾ç©ºé—´ï¼‰')
        logger.info('  - éª¨å¹²å¾®è°ƒ: å–å†³äºæ··åˆè®­ç»ƒæ¨¡å¼')
        logger.info('')
        
        # è¾“å‡ºé…ç½®
        config.log_stage_config(logger, "Stage 2")
        config.log_stage_config(logger, "Stage 3")
        
        # åŠ è½½æ•°æ®
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½æ•°æ®å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        X_train, y_train_true = _load_train_dataset()
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(åŠ è½½æ•°æ®å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        if X_train is None:
            raise RuntimeError('è®­ç»ƒæ•°æ®é›†åŠ è½½å¤±è´¥')

        y_corrected = y_train_true.astype(int)
        correction_weight = np.ones(len(y_corrected), dtype=np.float32)

        log_data_stats(logger, {
            "æ•°æ®å½¢çŠ¶": f"{X_train.shape} (æ ·æœ¬æ•°Ã—åºåˆ—é•¿åº¦Ã—ç‰¹å¾ç»´åº¦)",
            "è®­ç»ƒæ ·æœ¬æ€»æ•°": len(X_train),
            "æ­£å¸¸æ ·æœ¬": int((y_corrected == 0).sum()),
            "æ¶æ„æ ·æœ¬": int((y_corrected == 1).sum()),
            "æ•°æ®ç±»å‹": "åŸå§‹åºåˆ—ï¼ˆå°†è¿›è¡Œç‰¹å¾ç©ºé—´å¢å¼ºï¼‰"
        }, "åŸå§‹è®­ç»ƒæ•°æ®ç»Ÿè®¡")
        
        # æ„å»º/åŠ è½½éª¨å¹²ç½‘ç»œï¼ˆæ ¹æ®æ˜¯å¦é‡è®­å†³å®šï¼‰
        backbone = None
        backbone_path = args.backbone_path if args.backbone_path else os.path.join(config.FEATURE_EXTRACTION_DIR, 'models', 'backbone_pretrained.pth')

        if args.retrain_backbone:
            logger.info('ğŸ” é‡æ–°è®­ç»ƒéª¨å¹²ç½‘ç»œï¼ˆStage 1 è‡ªç›‘ç£é¢„è®­ç»ƒï¼‰...')
            log_input_paths(logger, {
                "è®­ç»ƒæ•°æ®(æ­£å¸¸)": config.BENIGN_TRAIN,
                "è®­ç»ƒæ•°æ®(æ¶æ„)": config.MALICIOUS_TRAIN,
            })
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1åˆ†æ”¯è¿›å…¥): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1-æ„å»ºbackboneå‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            backbone = build_backbone(config, logger=logger)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1-æ„å»ºbackboneå): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

            use_instance_contrastive = getattr(config, 'USE_INSTANCE_CONTRASTIVE', False)
            contrastive_method = getattr(config, 'CONTRASTIVE_METHOD', 'infonce')
            method_lower = str(contrastive_method).lower()
            if use_instance_contrastive and method_lower == 'nnclr':
                batch_size = getattr(config, 'PRETRAIN_BATCH_SIZE_NNCLR', 64)
            elif use_instance_contrastive and method_lower == 'simsiam':
                batch_size = getattr(config, 'PRETRAIN_BATCH_SIZE_SIMSIAM', config.PRETRAIN_BATCH_SIZE)
            else:
                batch_size = config.PRETRAIN_BATCH_SIZE

            dataset = TensorDataset(torch.FloatTensor(X_train))
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1-DataLoaderåˆ›å»ºå‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1-DataLoaderåˆ›å»ºå): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

            backbone = backbone.to(config.DEVICE)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1è®­ç»ƒå‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            backbone, _pretrain_history = stage1_pretrain_backbone(backbone, train_loader, config, logger)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1è®­ç»ƒå): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

            reseed_fp_before = _rng_fingerprint_short()
            set_seed(args.seed)
            reseed_fp_after = _rng_fingerprint_short()
            logger.info(
                f"ğŸ”§ RNGæŒ‡çº¹(Stage1åé‡ç½®seedå‰/å): {reseed_fp_before} -> {reseed_fp_after} ({_seed_snapshot(args.seed)})"
            )
            _advance_rng_to_stage2_baseline(logger, args.seed)

            default_backbone_path = os.path.join(config.FEATURE_EXTRACTION_DIR, 'models', 'backbone_pretrained.pth')
            if args.backbone_path:
                logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1ä¿å­˜å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
                torch.save(backbone.state_dict(), args.backbone_path)
                backbone_path = args.backbone_path
                logger.info(f'âœ“ å·²ä¿å­˜æ–°éª¨å¹²ç½‘ç»œ: {backbone_path}')
                logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1ä¿å­˜å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            else:
                backbone_path = default_backbone_path
                logger.info(f'âœ“ å·²ä¿å­˜æ–°éª¨å¹²ç½‘ç»œ: {backbone_path}')
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage1åˆ†æ”¯ç»“æŸ/è¿›å…¥Stage2å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        else:
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æ„å»ºbackboneå‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
            backbone = build_backbone(config, logger=logger)
            logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æ„å»ºbackboneå): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

            if os.path.exists(backbone_path):
                logger.info(f'âœ“ åŠ è½½éª¨å¹²ç½‘ç»œ: {backbone_path}')
                try:
                    state_dict = torch.load(backbone_path, map_location=config.DEVICE, weights_only=True)
                except TypeError:
                    state_dict = torch.load(backbone_path, map_location=config.DEVICE)
                backbone.load_state_dict(state_dict, strict=False)
                backbone.freeze()
            else:
                logger.warning('âš  ä½¿ç”¨éšæœºåˆå§‹åŒ–éª¨å¹²ç½‘ç»œ')
                backbone.freeze()
        
        # Stage 2: æ•°æ®å¢å¼ºï¼ˆè·³è¿‡æ ‡ç­¾çŸ«æ­£ï¼‰
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage2è°ƒç”¨å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        Z_aug, y_aug, w_aug, correction_stats, tabddpm, n_original = stage2_label_correction_and_augmentation(
            backbone, X_train, y_corrected, y_corrected, config, logger,
            stage2_mode='clean_augment_only'
        )
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage2è¿”å›å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

        # Stage 3: åˆ†ç±»å™¨è®­ç»ƒ
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage3è°ƒç”¨å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        # åŠ è½½åŸå§‹åºåˆ—ç”¨äºæ··åˆè®­ç»ƒ
        real_kept_path = os.path.join(config.DATA_AUGMENTATION_DIR, "models", "real_kept_data.npz")
        X_real = None
        use_mixed_stream = bool(getattr(config, 'STAGE3_MIXED_STREAM', True))
        
        if os.path.exists(real_kept_path) and use_mixed_stream:
            logger.info(f'âœ“ åŠ è½½åŸå§‹åºåˆ—: {real_kept_path}')
            real_data = np.load(real_kept_path)
            X_real = real_data['X_real']
            logger.info(f'  - åŸå§‹åºåˆ—å½¢çŠ¶: {X_real.shape}')
        else:
            use_mixed_stream = False
            logger.info('âš ï¸ æ··åˆè®­ç»ƒæ¨¡å¼å·²ç¦ç”¨')

        stage3_finetune_classifier(
            backbone, Z_aug, y_aug, w_aug, config, logger,
            n_original=n_original, backbone_path=backbone_path,
            X_train_real=X_real, use_mixed_stream=use_mixed_stream
        )
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(Stage3è¿”å›å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

        # æµ‹è¯•
        log_section_header(logger, "ğŸ§ª æµ‹è¯•è¯„ä¼°")
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æµ‹è¯•å‰): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")
        classifier_best = os.path.join(config.CLASSIFICATION_DIR, 'models', 'classifier_best_f1.pth')
        
        meta_path = os.path.join(config.CLASSIFICATION_DIR, 'models', 'model_metadata.json')
        backbone_path_for_test = backbone_path
        if os.path.exists(meta_path):
            with open(meta_path, 'r') as f:
                meta = json.load(f)
            bp = meta.get('backbone_path', '')
            if bp:
                if os.path.exists(bp):
                    backbone_path_for_test = bp
                    logger.info(f"âœ“ ä½¿ç”¨å…ƒæ•°æ®ä¸­è®°å½•çš„éª¨å¹²ç½‘ç»œ: {bp}")
                else:
                    logger.warning(f"âš  å…ƒæ•°æ®ä¸­è®°å½•çš„éª¨å¹²ç½‘ç»œä¸å­˜åœ¨: {bp}")
                    logger.warning(f"  å›é€€åˆ°è®­ç»ƒæ—¶ä½¿ç”¨çš„éª¨å¹²ç½‘ç»œ: {backbone_path}")

        test_args = argparse.Namespace(backbone_path=backbone_path_for_test)
        test_main(test_args)
        logger.info(f"ğŸ”§ RNGæŒ‡çº¹(æµ‹è¯•å): {_rng_fingerprint_short()} ({_seed_snapshot(args.seed)})")

        log_final_summary(logger, "å®Œæˆ", {}, {
            "è¿è¡Œç›®å½•": run_dir,
            "åˆ†ç±»å™¨": classifier_best,
            "æµ‹è¯•ç»“æœ": config.RESULT_DIR
        })
        
    finally:
        config.CLASSIFICATION_DIR = original_classification_dir
        config.RESULT_DIR = original_result_dir
        config.DATA_AUGMENTATION_DIR = original_data_aug_dir


if __name__ == '__main__':
    main()
