"""
MEDAL-Lite All-in-One Script
Runs complete training and testing pipeline
"""
import sys
import os
from pathlib import Path

# Ensure project root is on sys.path when running as a script
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

import argparse
from datetime import datetime

from MoudleCode.utils.config import config
from MoudleCode.utils.helpers import set_seed, setup_logger

# Import train and test functions
from scripts.training.train import main as train_main
from scripts.testing.test import main as test_main

# å¯¼å…¥é¢„å¤„ç†æ¨¡å—
try:
    from scripts.utils.preprocess import check_preprocessed_exists, preprocess_train, preprocess_test
    PREPROCESS_AVAILABLE = True
except ImportError:
    PREPROCESS_AVAILABLE = False

import logging


def main(args):
    """Main function to run both training and testing"""
    
    # Setup
    set_seed(config.SEED)
    config.create_dirs()
    logger = setup_logger(os.path.join(config.OUTPUT_ROOT, "logs"), name='all_train_test')
    
    logger.info("="*70)
    logger.info("ðŸš€ MEDAL-Lite Complete Pipeline: Training + Testing")
    logger.info("="*70)
    logger.info(f"è®¾å¤‡: {config.DEVICE}")
    logger.info(f"æ—¶é—´æˆ³: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("")
    logger.info("ðŸ“‹ å®žéªŒé…ç½®:")
    logger.info(f"  è®­ç»ƒé›†è·¯å¾„: {config.BENIGN_TRAIN} (æ­£å¸¸), {config.MALICIOUS_TRAIN} (æ¶æ„)")
    logger.info(f"  æµ‹è¯•é›†è·¯å¾„: {config.BENIGN_TEST} (æ­£å¸¸), {config.MALICIOUS_TEST} (æ¶æ„)")
    logger.info(f"  è¯´æ˜Ž: å°†è¯»å–ä¸Šè¿°è·¯å¾„ä¸‹æ‰€æœ‰pcapæ–‡ä»¶ï¼Œæµæ•°åœ¨å¤„ç†æ—¶ç»Ÿè®¡")
    logger.info(f"  æ ‡ç­¾å™ªå£°çŽ‡: {config.LABEL_NOISE_RATE*100:.0f}%")
    logger.info("")
    
    # Check start stage
    start_stage = getattr(args, 'start_stage', '1')
    
    # ========================
    # Phase 0: æ£€æŸ¥é¢„å¤„ç†æ•°æ®
    # ========================
    if PREPROCESS_AVAILABLE:
        logger.info("="*70)
        logger.info("ðŸ“¦ æ£€æŸ¥é¢„å¤„ç†æ•°æ®")
        logger.info("="*70)
        
        train_exists = check_preprocessed_exists('train')
        test_exists = check_preprocessed_exists('test')
        
        if train_exists:
            logger.info("âœ“ è®­ç»ƒé›†é¢„å¤„ç†æ–‡ä»¶å·²å­˜åœ¨")
        else:
            logger.info("âš ï¸  è®­ç»ƒé›†é¢„å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä»ŽPCAPåŠ è½½")
            logger.info("   ðŸ’¡ æç¤º: è¿è¡Œ 'python preprocess.py --train_only' å¯é¢„å¤„ç†è®­ç»ƒé›†")
        
        if test_exists:
            logger.info("âœ“ æµ‹è¯•é›†é¢„å¤„ç†æ–‡ä»¶å·²å­˜åœ¨")
        else:
            logger.info("âš ï¸  æµ‹è¯•é›†é¢„å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä»ŽPCAPåŠ è½½")
            logger.info("   ðŸ’¡ æç¤º: è¿è¡Œ 'python preprocess.py --test_only' å¯é¢„å¤„ç†æµ‹è¯•é›†")
        
        logger.info("")
    
    # ========================
    # Phase 1: Training (if not starting from test)
    # ========================
    if start_stage != "test":
        logger.info("="*70)
        logger.info("ðŸ“š PHASE 1: TRAINING è®­ç»ƒé˜¶æ®µ")
        logger.info("="*70)
        logger.info("")
        
        try:
            classifier = train_main(args)
            logger.info("")
            logger.info("âœ“ è®­ç»ƒé˜¶æ®µå®Œæˆ!")
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒé˜¶æ®µå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
    else:
        logger.info("="*70)
        logger.info("â­ï¸  è·³è¿‡è®­ç»ƒé˜¶æ®µ (ä»Žæµ‹è¯•å¼€å§‹)")
        logger.info("="*70)
        logger.info("")
    
    # ========================
    # Phase 2: Testing
    # ========================
    logger.info("")
    logger.info("="*70)
    logger.info("ðŸ§ª PHASE 2: TESTING æµ‹è¯•é˜¶æ®µ")
    logger.info("="*70)
    logger.info("")
    
    try:
        metrics = test_main(args)
        logger.info("")
        logger.info("âœ“ æµ‹è¯•é˜¶æ®µå®Œæˆ!")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•é˜¶æ®µå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ========================
    # Summary
    # ========================
    logger.info("")
    logger.info("="*70)
    logger.info("ðŸŽ‰ å®Œæ•´æµç¨‹å®Œæˆ - æœ€ç»ˆæ€»ç»“ PIPELINE COMPLETE - SUMMARY")
    logger.info("="*70)
    logger.info("")
    logger.info("ðŸ“Š æœ€ç»ˆæµ‹è¯•æ€§èƒ½:")
    logger.info(f"  âœ“ å‡†ç¡®çŽ‡ (Accuracy):  {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
    logger.info(f"  âœ“ ç²¾ç¡®çŽ‡ (Precision): {metrics['precision_pos']:.4f} ({metrics['precision_pos']*100:.2f}%)")
    logger.info(f"  âœ“ å¬å›žçŽ‡ (Recall):    {metrics['recall_pos']:.4f} ({metrics['recall_pos']*100:.2f}%)")
    logger.info(f"  âœ“ F1åˆ†æ•° (F1-pos):    {metrics['f1_pos']:.4f} ({metrics['f1_pos']*100:.2f}%)  # è®ºæ–‡å£å¾„")
    logger.info(f"  âœ“ F1-Macro:           {metrics['f1_macro']:.4f} ({metrics['f1_macro']*100:.2f}%)")
    if 'auc' in metrics:
        logger.info(f"  âœ“ AUCå€¼:              {metrics['auc']:.4f} ({metrics['auc']*100:.2f}%)")
    logger.info("")
    logger.info("ðŸ“ è¾“å‡ºæ–‡ä»¶ä½ç½®:")
    logger.info(f"  âœ“ æ¨¡åž‹æ–‡ä»¶: {config.CHECKPOINT_DIR}")
    logger.info(f"  âœ“ å¯è§†åŒ–å›¾è¡¨: {os.path.join(config.OUTPUT_ROOT, 'figures')}")
    logger.info(f"  âœ“ æµ‹è¯•ç»“æžœ: {os.path.join(config.OUTPUT_ROOT, 'result')}")
    logger.info(f"  âœ“ è®­ç»ƒæ—¥å¿—: {os.path.join(config.OUTPUT_ROOT, 'logs')}")
    logger.info("")
    logger.info("="*70)
    logger.info("æ„Ÿè°¢ä½¿ç”¨ MEDAL-Lite! Thank you for using MEDAL-Lite!")
    logger.info("="*70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Run complete MEDAL-Lite training and testing")
    
    # Training arguments
    parser.add_argument("--noise_rate", type=float, default=0.30, 
                       help="Label noise rate (default: 0.30)")
    
    # Stage selection
    parser.add_argument("--start_stage", type=str, default="1", 
                       choices=["1", "2", "3", "test"],
                       help="Start from which stage (1=backbone pretrain, 2=label correction, 3=classifier finetune, test=testing only)")
    
    # Backbone selection
    parser.add_argument("--backbone_path", type=str, default=None,
                       help="Path to specific backbone model (e.g., backbone_SimCLR_500.pth)")
    
    # Backbone finetuning arguments (Stage 3)
    parser.add_argument("--finetune_backbone", action="store_true",
                       help="Enable backbone finetuning in Stage 3 (default: False)")
    parser.add_argument("--finetune_backbone_lr", type=float, default=None,
                       help="Learning rate for backbone finetuning (default: 2e-5)")
    parser.add_argument("--finetune_backbone_warmup", type=int, default=None,
                       help="Warmup epochs before backbone finetuning (default: 30)")
    parser.add_argument("--finetune_backbone_scope", type=str, default=None,
                       choices=["projection", "all"],
                       help="Scope of backbone finetuning: projection or all (default: projection)")
    
    args = parser.parse_args()
    
    # Override config with arguments
    config.LABEL_NOISE_RATE = args.noise_rate
    
    # Apply backbone finetuning settings from command line or environment variables
    # Priority: command line args > environment variables > config defaults
    if args.finetune_backbone or os.environ.get('MEDAL_FINETUNE_BACKBONE', '').strip().lower() in ('1', 'true', 'yes', 'y', 'on'):
        config.FINETUNE_BACKBONE = True
        
        # Set learning rate
        if args.finetune_backbone_lr is not None:
            config.FINETUNE_BACKBONE_LR = args.finetune_backbone_lr
        elif os.environ.get('MEDAL_FINETUNE_BACKBONE_LR', '').strip():
            try:
                config.FINETUNE_BACKBONE_LR = float(os.environ.get('MEDAL_FINETUNE_BACKBONE_LR'))
            except ValueError:
                pass
        else:
            config.FINETUNE_BACKBONE_LR = 2e-5  # Default value
        
        # Set warmup epochs
        if args.finetune_backbone_warmup is not None:
            config.FINETUNE_BACKBONE_WARMUP_EPOCHS = args.finetune_backbone_warmup
        elif os.environ.get('MEDAL_FINETUNE_BACKBONE_WARMUP_EPOCHS', '').strip():
            try:
                config.FINETUNE_BACKBONE_WARMUP_EPOCHS = int(float(os.environ.get('MEDAL_FINETUNE_BACKBONE_WARMUP_EPOCHS')))
            except ValueError:
                pass
        else:
            config.FINETUNE_BACKBONE_WARMUP_EPOCHS = 30  # Default value
        
        # Set scope
        if args.finetune_backbone_scope is not None:
            config.FINETUNE_BACKBONE_SCOPE = args.finetune_backbone_scope
        elif os.environ.get('MEDAL_FINETUNE_BACKBONE_SCOPE', '').strip().lower() in ('projection', 'all'):
            config.FINETUNE_BACKBONE_SCOPE = os.environ.get('MEDAL_FINETUNE_BACKBONE_SCOPE').strip().lower()
        else:
            config.FINETUNE_BACKBONE_SCOPE = 'projection'  # Default value
    
    main(args)

