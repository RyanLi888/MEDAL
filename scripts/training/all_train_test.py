"""
MEDAL-Lite å®Œæ•´è®­ç»ƒ+æµ‹è¯•è„šæœ¬ (é‡æ„ç‰ˆ)
=====================================
è¿è¡Œå®Œæ•´çš„è®­ç»ƒå’Œæµ‹è¯•æµç¨‹ï¼Œå¤ç”¨ä¸»æµç¨‹ä»£ç 
"""
import sys
import os
from pathlib import Path

project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

import argparse
from datetime import datetime
import hashlib
import random
import json

from MoudleCode.utils.config import config
from MoudleCode.utils.helpers import set_seed, setup_logger
from MoudleCode.utils.logging_utils import (
    log_section_header, log_data_stats, log_final_summary, log_output_paths
)

import numpy as np
import torch

from scripts.training.train import main as train_main
from scripts.testing.test import main as test_main

try:
    from scripts.utils.preprocess import check_preprocessed_exists
    PREPROCESS_AVAILABLE = True
except ImportError:
    PREPROCESS_AVAILABLE = False


def _safe_makedirs(path: str) -> None:
    """å®‰å…¨åˆ›å»ºç›®å½•"""
    os.makedirs(path, exist_ok=True)


def main(args):
    """ä¸»å‡½æ•°ï¼šè¿è¡Œè®­ç»ƒå’Œæµ‹è¯•"""

    def _rng_fingerprint_short() -> str:
        h = hashlib.sha256()
        try:
            h.update(repr(random.getstate()).encode('utf-8'))
        except Exception:
            h.update(b'py_random_error')
        try:
            ns = np.random.get_state()
            h.update(str(ns[0]).encode('utf-8'))
            h.update(np.asarray(ns[1], dtype=np.uint32).tobytes())
            h.update(str(ns[2]).encode('utf-8'))
            h.update(str(ns[3]).encode('utf-8'))
            h.update(str(ns[4]).encode('utf-8'))
        except Exception:
            h.update(b'numpy_random_error')
        try:
            h.update(torch.get_rng_state().detach().cpu().numpy().tobytes())
        except Exception:
            h.update(b'torch_cpu_rng_error')
        try:
            if torch.cuda.is_available():
                for s in torch.cuda.get_rng_state_all():
                    h.update(s.detach().cpu().numpy().tobytes())
            else:
                h.update(b'no_cuda')
        except Exception:
            h.update(b'torch_cuda_rng_error')
        return h.hexdigest()[:16]

    seed = getattr(args, 'seed', None) or getattr(config, 'SEED', None) or 42
    config.SEED = seed
    rng_fp_before_seed = _rng_fingerprint_short()
    set_seed(seed)
    rng_fp_after_seed = _rng_fingerprint_short()
    config.create_dirs()
    
    # å¦‚æœæŒ‡å®šäº†å®éªŒç›®å½•ï¼ˆç”¨äºæµ‹è¯•ï¼‰ï¼ŒåŠ è½½å®éªŒå…ƒæ•°æ®å¹¶è®¾ç½®è¾“å‡ºç›®å½•
    if getattr(args, 'experiment_dir', None):
        experiment_dir = args.experiment_dir
        metadata_path = os.path.join(experiment_dir, 'experiment_metadata.json')
        if os.path.exists(metadata_path):
            with open(metadata_path, 'r', encoding='utf-8') as f:
                experiment_metadata = json.load(f)
            dirs = experiment_metadata.get('directories', {})
            config.FEATURE_EXTRACTION_DIR = dirs.get('feature_extraction', config.FEATURE_EXTRACTION_DIR)
            config.LABEL_CORRECTION_DIR = dirs.get('label_correction', config.LABEL_CORRECTION_DIR)
            config.DATA_AUGMENTATION_DIR = dirs.get('data_augmentation', config.DATA_AUGMENTATION_DIR)
            config.CLASSIFICATION_DIR = dirs.get('classification', config.CLASSIFICATION_DIR)
            config.RESULT_DIR = dirs.get('result', config.RESULT_DIR)
            run_tag = experiment_metadata.get('run_tag', os.path.basename(experiment_dir))
        else:
            logger.warning(f"âš  å®éªŒå…ƒæ•°æ®ä¸å­˜åœ¨: {metadata_path}")
            logger.warning("  ä½¿ç”¨é»˜è®¤è¾“å‡ºç›®å½•")
            run_tag = os.path.basename(experiment_dir)
    else:
        # åˆ›å»ºæ–°çš„å®éªŒæ–‡ä»¶å¤¹ï¼ˆåŸºäºæ—¶é—´æˆ³ï¼‰
        run_tag = getattr(args, 'run_tag', None) or datetime.now().strftime('%Y%m%d_%H%M%S')
        experiment_dir = os.path.join(config.OUTPUT_ROOT, 'experiments', run_tag)
        _safe_makedirs(experiment_dir)
        
        # ä¿å­˜åŸå§‹è¾“å‡ºç›®å½•
        original_feature_extraction_dir = config.FEATURE_EXTRACTION_DIR
        original_label_correction_dir = config.LABEL_CORRECTION_DIR
        original_data_augmentation_dir = config.DATA_AUGMENTATION_DIR
        original_classification_dir = config.CLASSIFICATION_DIR
        original_result_dir = config.RESULT_DIR
        
        # ä¿®æ”¹è¾“å‡ºç›®å½•ï¼Œä½¿å…¶æŒ‡å‘å®éªŒæ–‡ä»¶å¤¹
        config.FEATURE_EXTRACTION_DIR = os.path.join(experiment_dir, 'feature_extraction')
        config.LABEL_CORRECTION_DIR = os.path.join(experiment_dir, 'label_correction')
        config.DATA_AUGMENTATION_DIR = os.path.join(experiment_dir, 'data_augmentation')
        config.CLASSIFICATION_DIR = os.path.join(experiment_dir, 'classification')
        config.RESULT_DIR = os.path.join(experiment_dir, 'result')
        
        # åˆ›å»ºå®éªŒæ–‡ä»¶å¤¹ä¸‹çš„å­ç›®å½•
        for module_dir in [config.FEATURE_EXTRACTION_DIR, config.LABEL_CORRECTION_DIR,
                          config.DATA_AUGMENTATION_DIR, config.CLASSIFICATION_DIR, config.RESULT_DIR]:
            _safe_makedirs(module_dir)
            _safe_makedirs(os.path.join(module_dir, 'models'))
            _safe_makedirs(os.path.join(module_dir, 'figures'))
            _safe_makedirs(os.path.join(module_dir, 'logs'))
        
        # ä¿å­˜å®éªŒå…ƒæ•°æ®
        experiment_metadata = {
            'run_tag': run_tag,
            'experiment_dir': experiment_dir,
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'seed': seed,
            'start_stage': getattr(args, 'start_stage', '1'),
            'backbone_path': getattr(args, 'backbone_path', None),
            'noise_rate': config.LABEL_NOISE_RATE,
            'directories': {
                'feature_extraction': config.FEATURE_EXTRACTION_DIR,
                'label_correction': config.LABEL_CORRECTION_DIR,
                'data_augmentation': config.DATA_AUGMENTATION_DIR,
                'classification': config.CLASSIFICATION_DIR,
                'result': config.RESULT_DIR,
            }
        }
        metadata_path = os.path.join(experiment_dir, 'experiment_metadata.json')
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(experiment_metadata, f, ensure_ascii=False, indent=2)
    
    # åˆ›å»ºæ—¥å¿—ç›®å½•
    log_dir = os.path.join(experiment_dir, 'logs')
    _safe_makedirs(log_dir)
    logger = setup_logger(log_dir, name='all_train_test')

    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå‰): {rng_fp_before_seed}")
    logger.info(f"ğŸ”§ RNGæŒ‡çº¹(seedå): {rng_fp_after_seed} (args.seed={seed} | config.SEED={int(getattr(config, 'SEED', -1))} | torch.initial_seed={int(torch.initial_seed()) if hasattr(torch, 'initial_seed') else 'N/A'})")
    
    log_section_header(logger, "ğŸš€ MEDAL-Lite å®Œæ•´æµç¨‹: è®­ç»ƒ + æµ‹è¯•")
    logger.info(f"è®¾å¤‡: {config.DEVICE}")
    logger.info(f"æ—¶é—´æˆ³: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"å®éªŒç›®å½•: {experiment_dir}")
    logger.info(f"å®éªŒæ ‡ç­¾: {run_tag}")
    
    # è¾“å‡ºé…ç½®æ‘˜è¦
    logger.info("")
    logger.info("ğŸ“‹ å®éªŒé…ç½®:")
    logger.info(f"  è®­ç»ƒé›†: {config.BENIGN_TRAIN}, {config.MALICIOUS_TRAIN}")
    logger.info(f"  æµ‹è¯•é›†: {config.BENIGN_TEST}, {config.MALICIOUS_TEST}")
    logger.info(f"  æ ‡ç­¾å™ªå£°ç‡: {config.LABEL_NOISE_RATE*100:.0f}%")
    logger.info("")
    
    if not getattr(args, 'experiment_dir', None):
        logger.info(f"âœ“ å®éªŒå…ƒæ•°æ®å·²ä¿å­˜: {metadata_path}")
        logger.info("")
    
    start_stage = getattr(args, 'start_stage', '1')
    
    # æ£€æŸ¥é¢„å¤„ç†æ•°æ®
    if PREPROCESS_AVAILABLE:
        log_section_header(logger, "ğŸ“¦ æ£€æŸ¥é¢„å¤„ç†æ•°æ®")
        train_exists = check_preprocessed_exists('train')
        test_exists = check_preprocessed_exists('test')
        
        logger.info(f"è®­ç»ƒé›†é¢„å¤„ç†: {'âœ“ å­˜åœ¨' if train_exists else 'âš ï¸ ä¸å­˜åœ¨'}")
        logger.info(f"æµ‹è¯•é›†é¢„å¤„ç†: {'âœ“ å­˜åœ¨' if test_exists else 'âš ï¸ ä¸å­˜åœ¨'}")
        logger.info("")
    
    # è®­ç»ƒé˜¶æ®µ
    if start_stage != "test":
        log_section_header(logger, "ğŸ“š PHASE 1: è®­ç»ƒé˜¶æ®µ")
        
        try:
            classifier = train_main(args)
            logger.info("âœ“ è®­ç»ƒé˜¶æ®µå®Œæˆ!")
        except Exception as e:
            logger.error(f"âŒ è®­ç»ƒé˜¶æ®µå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return
    else:
        logger.info("â­ï¸ è·³è¿‡è®­ç»ƒé˜¶æ®µ")
    
    # æµ‹è¯•é˜¶æ®µ
    log_section_header(logger, "ğŸ§ª PHASE 2: æµ‹è¯•é˜¶æ®µ")
    
    try:
        # ç¡®ä¿æµ‹è¯•æ—¶ä½¿ç”¨å®éªŒç›®å½•ä¸­çš„æ¨¡å‹
        # å¦‚æœbackbone_pathæœªæŒ‡å®šï¼Œå°è¯•ä»å®éªŒç›®å½•åŠ è½½
        if not getattr(args, 'backbone_path', None):
            # å°è¯•ä»åˆ†ç±»å™¨å…ƒæ•°æ®ä¸­è·å–backboneè·¯å¾„
            classifier_metadata_path = os.path.join(config.CLASSIFICATION_DIR, 'models', 'model_metadata.json')
            if os.path.exists(classifier_metadata_path):
                with open(classifier_metadata_path, 'r', encoding='utf-8') as f:
                    classifier_metadata = json.load(f)
                backbone_path_from_meta = classifier_metadata.get('backbone_path')
                if backbone_path_from_meta and os.path.exists(backbone_path_from_meta):
                    args.backbone_path = backbone_path_from_meta
                    logger.info(f"âœ“ ä»åˆ†ç±»å™¨å…ƒæ•°æ®è·å–éª¨å¹²ç½‘ç»œè·¯å¾„: {backbone_path_from_meta}")
                else:
                    # å°è¯•ä½¿ç”¨å®éªŒç›®å½•ä¸­çš„backbone
                    experiment_backbone = os.path.join(config.FEATURE_EXTRACTION_DIR, 'models', 'backbone_pretrained.pth')
                    if os.path.exists(experiment_backbone):
                        args.backbone_path = experiment_backbone
                        logger.info(f"âœ“ ä½¿ç”¨å®éªŒç›®å½•ä¸­çš„éª¨å¹²ç½‘ç»œ: {experiment_backbone}")
        
        metrics = test_main(args)
        logger.info("âœ“ æµ‹è¯•é˜¶æ®µå®Œæˆ!")
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•é˜¶æ®µå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # æœ€ç»ˆæ€»ç»“
    log_final_summary(logger, "å®Œæ•´æµç¨‹å®Œæˆ", {
        "å‡†ç¡®ç‡": metrics['accuracy'],
        "ç²¾ç¡®ç‡": metrics['precision_pos'],
        "å¬å›ç‡": metrics['recall_pos'],
        "F1åˆ†æ•°": metrics['f1_pos'],
        "AUC": metrics.get('auc', 'N/A')
    }, {
        "å®éªŒç›®å½•": experiment_dir,
        "éª¨å¹²ç½‘ç»œ": os.path.join(config.FEATURE_EXTRACTION_DIR, 'models'),
        "æ ‡ç­¾çŸ«æ­£": os.path.join(config.LABEL_CORRECTION_DIR, 'models'),
        "æ•°æ®å¢å¼º": os.path.join(config.DATA_AUGMENTATION_DIR, 'models'),
        "åˆ†ç±»å™¨": os.path.join(config.CLASSIFICATION_DIR, 'models'),
        "æµ‹è¯•ç»“æœ": config.RESULT_DIR,
        "è®­ç»ƒæ—¥å¿—": log_dir
    })
    
    # æ¢å¤åŸå§‹è¾“å‡ºç›®å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œä¸æ¢å¤ï¼Œå› ä¸ºåç»­å¯èƒ½è¿˜éœ€è¦ä½¿ç”¨å®éªŒç›®å½•
    # config.FEATURE_EXTRACTION_DIR = original_feature_extraction_dir
    # config.LABEL_CORRECTION_DIR = original_label_correction_dir
    # config.DATA_AUGMENTATION_DIR = original_data_augmentation_dir
    # config.CLASSIFICATION_DIR = original_classification_dir
    # config.RESULT_DIR = original_result_dir


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MEDAL-Lite å®Œæ•´è®­ç»ƒ+æµ‹è¯•")
    
    parser.add_argument("--noise_rate", type=float, default=None, help="æ ‡ç­¾å™ªå£°ç‡ï¼ˆé»˜è®¤ä½¿ç”¨config.LABEL_NOISE_RATEï¼‰")
    parser.add_argument("--start_stage", type=str, default="1", 
                       choices=["1", "2", "3", "test"], help="èµ·å§‹é˜¶æ®µ")
    parser.add_argument("--backbone_path", type=str, default=None, help="éª¨å¹²ç½‘ç»œè·¯å¾„")
    parser.add_argument("--finetune_backbone", action="store_true", help="å¯ç”¨éª¨å¹²å¾®è°ƒ")
    parser.add_argument("--seed", type=int, default=None, help="éšæœºç§å­ï¼ˆè¦†ç›–config.SEEDï¼‰")
    parser.add_argument("--run_tag", type=str, default=None, help="å®éªŒæ ‡ç­¾ï¼ˆé»˜è®¤ä½¿ç”¨æ—¶é—´æˆ³ï¼‰")
    parser.add_argument("--experiment_dir", type=str, default=None, help="å®éªŒç›®å½•è·¯å¾„ï¼ˆç”¨äºæµ‹è¯•æ—¶æŒ‡å®šï¼‰")
    
    args = parser.parse_args()
    if args.noise_rate is not None:
        config.LABEL_NOISE_RATE = args.noise_rate
    
    if args.finetune_backbone:
        config.FINETUNE_BACKBONE = True
    
    main(args)
