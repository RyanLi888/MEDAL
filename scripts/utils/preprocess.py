"""
MEDAL-Lite æ•°æ®é¢„å¤„ç†è„šæœ¬
========================

å°†PCAPæ–‡ä»¶é¢„å¤„ç†ä¸º.npyæ–‡ä»¶ï¼Œä¾›è®­ç»ƒå’Œæµ‹è¯•ç›´æ¥ä½¿ç”¨ã€‚
é¢„å¤„ç†åçš„æ–‡ä»¶ä¿å­˜åœ¨ output/preprocessed/ ç›®å½•ä¸‹ã€‚

ä½¿ç”¨æ–¹æ³•:
    # é¢„å¤„ç†æ‰€æœ‰æ•°æ®ï¼ˆè®­ç»ƒé›†+æµ‹è¯•é›†ï¼‰
    python preprocess.py
    
    # ä»…é¢„å¤„ç†è®­ç»ƒé›†
    python preprocess.py --train_only
    
    # ä»…é¢„å¤„ç†æµ‹è¯•é›†
    python preprocess.py --test_only
    
    # å¼ºåˆ¶é‡æ–°é¢„å¤„ç†ï¼ˆè¦†ç›–å·²æœ‰æ–‡ä»¶ï¼‰
    python preprocess.py --force

é¢„å¤„ç†åçš„æ–‡ä»¶:
    output/preprocessed/
    â”œâ”€â”€ train_X.npy      # è®­ç»ƒé›†ç‰¹å¾ (N, 1024, 4)
    â”œâ”€â”€ train_y.npy      # è®­ç»ƒé›†æ ‡ç­¾ (N,)
    â”œâ”€â”€ train_files.npy  # è®­ç»ƒé›†æ–‡ä»¶å
    â”œâ”€â”€ test_X.npy       # æµ‹è¯•é›†ç‰¹å¾ (M, 1024, 4)
    â”œâ”€â”€ test_y.npy       # æµ‹è¯•é›†æ ‡ç­¾ (M,)
    â””â”€â”€ test_files.npy   # æµ‹è¯•é›†æ–‡ä»¶å
"""
import sys
import os
from pathlib import Path

# Ensure project root is on sys.path when running as a script
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

import numpy as np
import argparse
import time
from datetime import datetime

from MoudleCode.utils.config import config
from MoudleCode.utils.helpers import setup_logger
from MoudleCode.preprocessing.pcap_parser import load_dataset

import logging

logger = setup_logger(os.path.join(config.OUTPUT_ROOT, "logs"), name='preprocess')


def get_preprocessed_dir():
    """è·å–é¢„å¤„ç†æ•°æ®ç›®å½•"""
    preprocessed_dir = os.path.join(config.OUTPUT_ROOT, "preprocessed")
    os.makedirs(preprocessed_dir, exist_ok=True)
    return preprocessed_dir


def check_preprocessed_exists(data_type='train'):
    """
    æ£€æŸ¥é¢„å¤„ç†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    Args:
        data_type: 'train' æˆ– 'test'
        
    Returns:
        bool: æ˜¯å¦å­˜åœ¨å®Œæ•´çš„é¢„å¤„ç†æ–‡ä»¶
    """
    preprocessed_dir = get_preprocessed_dir()
    
    required_files = [
        f'{data_type}_X.npy',
        f'{data_type}_y.npy',
        f'{data_type}_files.npy'
    ]
    
    for f in required_files:
        if not os.path.exists(os.path.join(preprocessed_dir, f)):
            return False
    return True


def load_preprocessed(data_type='train'):
    """
    åŠ è½½é¢„å¤„ç†åçš„æ•°æ®
    
    Args:
        data_type: 'train' æˆ– 'test'
        
    Returns:
        X: numpy array (N, L, 4)
        y: numpy array (N,)
        files: list of filenames
    """
    preprocessed_dir = get_preprocessed_dir()
    
    X = np.load(os.path.join(preprocessed_dir, f'{data_type}_X.npy'))
    y = np.load(os.path.join(preprocessed_dir, f'{data_type}_y.npy'))
    files = np.load(os.path.join(preprocessed_dir, f'{data_type}_files.npy'), allow_pickle=True)
    
    return X, y, files.tolist()


def normalize_burstsize_inplace(X: np.ndarray) -> np.ndarray:
    try:
        enabled = bool(getattr(config, 'BURSTSIZE_NORMALIZE', False))
    except Exception:
        enabled = False
    if not enabled:
        return X

    try:
        burst_idx = int(getattr(config, 'BURST_SIZE_INDEX', 2))
        vm_idx = int(getattr(config, 'VALID_MASK_INDEX', 3))
        denom = float(getattr(config, 'BURSTSIZE_NORM_DENOM', 1.0))
    except Exception:
        return X

    if denom <= 0:
        return X
    if X is None or getattr(X, 'ndim', 0) != 3:
        return X
    if burst_idx < 0 or burst_idx >= X.shape[-1] or vm_idx < 0 or vm_idx >= X.shape[-1]:
        return X

    mask = X[:, :, vm_idx] > 0.5
    X[:, :, burst_idx][mask] = X[:, :, burst_idx][mask] / denom
    return X


def save_preprocessed(X, y, files, data_type='train'):
    """
    ä¿å­˜é¢„å¤„ç†åçš„æ•°æ®
    
    Args:
        X: numpy array (N, L, 4)
        y: numpy array (N,)
        files: list of filenames
        data_type: 'train' æˆ– 'test'
    """
    preprocessed_dir = get_preprocessed_dir()
    
    np.save(os.path.join(preprocessed_dir, f'{data_type}_X.npy'), X)
    np.save(os.path.join(preprocessed_dir, f'{data_type}_y.npy'), y)
    np.save(os.path.join(preprocessed_dir, f'{data_type}_files.npy'), np.array(files, dtype=object))
    
    logger.info(f"âœ“ {data_type}æ•°æ®å·²ä¿å­˜åˆ° {preprocessed_dir}/")
    logger.info(f"  {data_type}_X.npy: {X.shape}")
    logger.info(f"  {data_type}_y.npy: {y.shape}")
    logger.info(f"  {data_type}_files.npy: {len(files)} ä¸ªæ–‡ä»¶å")


def preprocess_train(force=False):
    """
    é¢„å¤„ç†è®­ç»ƒé›†
    
    Args:
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°é¢„å¤„ç†
        
    Returns:
        X, y, files
    """
    if not force and check_preprocessed_exists('train'):
        logger.info("âœ“ è®­ç»ƒé›†é¢„å¤„ç†æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡é¢„å¤„ç†")
        return load_preprocessed('train')
    
    logger.info("="*70)
    logger.info("ğŸ“¦ é¢„å¤„ç†è®­ç»ƒé›† PCAP æ–‡ä»¶")
    logger.info("="*70)
    logger.info(f"æ­£å¸¸æµé‡ç›®å½•: {config.BENIGN_TRAIN}")
    logger.info(f"æ¶æ„æµé‡ç›®å½•: {config.MALICIOUS_TRAIN}")
    logger.info("")
    
    start_time = time.time()
    
    X_train, y_train, train_files = load_dataset(
        benign_dir=config.BENIGN_TRAIN,
        malicious_dir=config.MALICIOUS_TRAIN,
        sequence_length=config.SEQUENCE_LENGTH
    )
    
    elapsed = time.time() - start_time
    
    if X_train is None:
        logger.error("âŒ è®­ç»ƒé›†é¢„å¤„ç†å¤±è´¥!")
        return None, None, None
    
    logger.info("")
    logger.info(f"â±ï¸  è®­ç»ƒé›†é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)")
    logger.info(f"  æ•°æ®å½¢çŠ¶: {X_train.shape}")
    logger.info(f"  æ­£å¸¸æ ·æœ¬: {(y_train==0).sum()}")
    logger.info(f"  æ¶æ„æ ·æœ¬: {(y_train==1).sum()}")
    
    # ä¿å­˜é¢„å¤„ç†ç»“æœ
    save_preprocessed(X_train, y_train, train_files, 'train')
    
    return X_train, y_train, train_files


def preprocess_test(force=False):
    """
    é¢„å¤„ç†æµ‹è¯•é›†
    
    Args:
        force: æ˜¯å¦å¼ºåˆ¶é‡æ–°é¢„å¤„ç†
        
    Returns:
        X, y, files
    """
    if not force and check_preprocessed_exists('test'):
        logger.info("âœ“ æµ‹è¯•é›†é¢„å¤„ç†æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡é¢„å¤„ç†")
        return load_preprocessed('test')
    
    logger.info("="*70)
    logger.info("ğŸ“¦ é¢„å¤„ç†æµ‹è¯•é›† PCAP æ–‡ä»¶")
    logger.info("="*70)
    logger.info(f"æ­£å¸¸æµé‡ç›®å½•: {config.BENIGN_TEST}")
    logger.info(f"æ¶æ„æµé‡ç›®å½•: {config.MALICIOUS_TEST}")
    logger.info("")
    logger.info("âš ï¸  æµ‹è¯•é›†å¯èƒ½åŒ…å«å¤§æ–‡ä»¶ï¼Œé¢„è®¡è€—æ—¶è¾ƒé•¿...")
    logger.info("")
    
    start_time = time.time()
    
    X_test, y_test, test_files = load_dataset(
        benign_dir=config.BENIGN_TEST,
        malicious_dir=config.MALICIOUS_TEST,
        sequence_length=config.SEQUENCE_LENGTH
    )
    
    elapsed = time.time() - start_time
    
    if X_test is None:
        logger.error("âŒ æµ‹è¯•é›†é¢„å¤„ç†å¤±è´¥!")
        return None, None, None
    
    logger.info("")
    logger.info(f"â±ï¸  æµ‹è¯•é›†é¢„å¤„ç†å®Œæˆï¼Œè€—æ—¶: {elapsed:.1f}ç§’ ({elapsed/60:.1f}åˆ†é’Ÿ)")
    logger.info(f"  æ•°æ®å½¢çŠ¶: {X_test.shape}")
    logger.info(f"  æ­£å¸¸æ ·æœ¬: {(y_test==0).sum()}")
    logger.info(f"  æ¶æ„æ ·æœ¬: {(y_test==1).sum()}")
    
    # ä¿å­˜é¢„å¤„ç†ç»“æœ
    save_preprocessed(X_test, y_test, test_files, 'test')
    
    return X_test, y_test, test_files


def main(args):
    """ä¸»å‡½æ•°"""
    logger.info("="*70)
    logger.info("ğŸš€ MEDAL-Lite æ•°æ®é¢„å¤„ç†")
    logger.info("="*70)
    logger.info(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"å¼ºåˆ¶é‡æ–°é¢„å¤„ç†: {args.force}")
    logger.info("")
    
    total_start = time.time()
    
    # é¢„å¤„ç†è®­ç»ƒé›†
    if not args.test_only:
        X_train, y_train, train_files = preprocess_train(force=args.force)
        if X_train is None:
            return
    
    # é¢„å¤„ç†æµ‹è¯•é›†
    if not args.train_only:
        X_test, y_test, test_files = preprocess_test(force=args.force)
        if X_test is None:
            return
    
    total_elapsed = time.time() - total_start
    
    logger.info("")
    logger.info("="*70)
    logger.info("ğŸ‰ é¢„å¤„ç†å®Œæˆ!")
    logger.info("="*70)
    logger.info(f"æ€»è€—æ—¶: {total_elapsed:.1f}ç§’ ({total_elapsed/60:.1f}åˆ†é’Ÿ)")
    logger.info("")
    logger.info("ğŸ“ é¢„å¤„ç†æ–‡ä»¶ä½ç½®:")
    logger.info(f"  {get_preprocessed_dir()}/")
    logger.info("")
    logger.info("ğŸ’¡ åç»­ä½¿ç”¨:")
    logger.info("  è®­ç»ƒ: python train.py")
    logger.info("  æµ‹è¯•: python test.py")
    logger.info("  å®Œæ•´æµç¨‹: python all_train_test.py")
    logger.info("="*70)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="MEDAL-Lite æ•°æ®é¢„å¤„ç†")
    
    parser.add_argument("--train_only", action="store_true",
                       help="ä»…é¢„å¤„ç†è®­ç»ƒé›†")
    parser.add_argument("--test_only", action="store_true",
                       help="ä»…é¢„å¤„ç†æµ‹è¯•é›†")
    parser.add_argument("--force", action="store_true",
                       help="å¼ºåˆ¶é‡æ–°é¢„å¤„ç†ï¼ˆè¦†ç›–å·²æœ‰æ–‡ä»¶ï¼‰")
    
    args = parser.parse_args()
    
    main(args)
