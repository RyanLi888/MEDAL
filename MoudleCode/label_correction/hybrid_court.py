"""
Hybrid Court: Label Noise Correction Module
ä¸¤é˜¶æ®µæ ‡ç­¾çŸ«æ­£ç­–ç•¥ (CL + AUM + KNN):

é˜¶æ®µ1: Keepå’ŒFlipå†³ç­–
    - ä½¿ç”¨CLï¼ˆé™æ€ç‰¹å¾åº¦é‡ï¼‰ã€AUMï¼ˆåŠ¨æ€è®­ç»ƒåº¦é‡ï¼‰å’ŒKNNï¼ˆé‚»å±…æŠ•ç¥¨ï¼‰è¿›è¡Œå†³ç­–
    - æ”¯æŒä¿å®ˆæ¨¡å¼ï¼ˆConservativeï¼‰å’Œæ¿€è¿›æ¨¡å¼ï¼ˆAggressiveï¼‰

é˜¶æ®µ2: ä¿å®ˆè¡¥åˆ€/æ•‘æ´ï¼ˆå¯é€‰ï¼‰
    - LateFlip: Phase1ä¿æŒä½†Stage2æŒ‡æ ‡æ˜¾ç¤ºåº”ç¿»è½¬çš„æ ·æœ¬
    - UndoFlip: Phase1ç¿»è½¬ä½†Stage2æŒ‡æ ‡æ˜¾ç¤ºåº”æ’¤é”€çš„æ ·æœ¬

æ ¸å¿ƒåŸåˆ™: ä½¿ç”¨CLã€AUMå’ŒKNNä¸‰é‡æ ¡éªŒè¿›è¡Œæ ‡ç­¾çŸ«æ­£
"""
import numpy as np
import torch
import torch.nn as nn
import copy
from sklearn.model_selection import KFold
from sklearn.neighbors import NearestNeighbors
from sklearn.linear_model import LogisticRegression
from cleanlab.filter import find_label_issues
import logging

from .hybrid_court_cl_aum import correct_labels_cl_aum

logger = logging.getLogger(__name__)

class CLProjectionHead(nn.Module):
    """
    ä¼˜åŒ–å»ºè®®2: ä¸ºCLåˆ›å»ºç‹¬ç«‹çš„æŠ•å½±å¤´
    ä¸“é—¨ç”¨äºè®¡ç®—CLçš„ç½®ä¿¡åº¦å’ŒKNNè·ç¦»ï¼Œä¸åˆ†ç±»MLPåˆ†ç¦»
    è®¾è®¡: è¾ƒå°çš„MLP (ä¾‹å¦‚ 256 -> 128 -> 64)
    """
    def __init__(self, input_dim, hidden_dim=128, output_dim=64):
        super().__init__()
        self.projection = nn.Sequential(
        nn.Linear(input_dim, hidden_dim),
        nn.LayerNorm(hidden_dim),  # ä½¿ç”¨LayerNormè€ŒéBatchNorm
        nn.ReLU(),
        nn.Dropout(0.1),
        nn.Linear(hidden_dim, output_dim),
        nn.LayerNorm(output_dim),
        )
    
    def forward(self, x):
        """
        Args:
        x: (B, input_dim) - Mambaè¾“å‡ºçš„ç‰¹å¾å‘é‡
        Returns:
        z: (B, output_dim) - æŠ•å½±åçš„ç‰¹å¾ï¼Œç”¨äºCLå’ŒKNN
        """
        return self.projection(x)


class ConfidentLearning:
    """Confident Learning (CL) - Probabilistic Diagnosis with Projection Head"""
    
    def __init__(self, n_folds=5, use_projection_head=True, feature_dim=32, device='cpu', config=None):
        self.n_folds = n_folds
        self.use_projection_head = use_projection_head
        self.device = device
        self.confident_joint = None
        self.thresholds = None
        
        # ä¼˜åŒ–å»ºè®®2: åˆ›å»ºç‹¬ç«‹çš„æŠ•å½±å¤´
        if use_projection_head:
            self.projection_head = CLProjectionHead(
                input_dim=feature_dim,
                hidden_dim=128,
                output_dim=64
            ).to(device)
            # ä¼˜åŒ–å»ºè®®2: æŠ•å½±å¤´è®­ç»ƒæ¨¡å¼é…ç½®
            # é»˜è®¤å†»ç»“ï¼ˆæ¨ç†æ¨¡å¼ï¼‰ï¼Œå¦‚æœéœ€è¦è®­ç»ƒå¯é€šè¿‡é…ç½®å¯ç”¨
            if config is not None:
                self.projection_trainable = getattr(config, 'CL_PROJECTION_TRAINABLE', False)
            else:
                self.projection_trainable = False
            if not self.projection_trainable:
                self.projection_head.eval()  # æ¨ç†æ¨¡å¼ï¼ˆå†»ç»“ï¼‰
                for param in self.projection_head.parameters():
                    param.requires_grad = False
            else:
                self.projection_head.train()  # è®­ç»ƒæ¨¡å¼
        else:
            self.projection_head = None
    
    def fit_predict(self, features, labels):
        """
        Args:
        features: (N, D) - Mambaæå–çš„ç‰¹å¾å‘é‡
        labels: (N,) - å™ªå£°æ ‡ç­¾
        """
        n_samples = len(labels)
        n_classes = len(np.unique(labels))
        
        # ä¼˜åŒ–å»ºè®®2: å¦‚æœä½¿ç”¨æŠ•å½±å¤´ï¼Œå…ˆæŠ•å½±ç‰¹å¾
        if self.use_projection_head and self.projection_head is not None:
            features_tensor = torch.FloatTensor(features).to(self.device)
            with torch.no_grad():
                features_projected = self.projection_head(features_tensor).cpu().numpy()
            features_for_cl = features_projected
        else:
            features_for_cl = features
        
        pred_probs = np.zeros((n_samples, n_classes))
        
        kf = KFold(n_splits=self.n_folds, shuffle=True, random_state=42)
        
        for train_idx, val_idx in kf.split(features_for_cl):
            X_train, X_val = features_for_cl[train_idx], features_for_cl[val_idx]
            y_train = labels[train_idx]
            clf = LogisticRegression(max_iter=1000, random_state=42)
            clf.fit(X_train, y_train)
            pred_probs[val_idx] = clf.predict_proba(X_val)

            label_issues = find_label_issues(labels=labels, pred_probs=pred_probs)
        suspected_noise_mask = label_issues.astype(bool)
        pred_labels = np.argmax(pred_probs, axis=1)
        
        self.last_suspected_noise = suspected_noise_mask
        self.last_pred_labels = pred_labels
        self.last_pred_probs = pred_probs
        
        logger.info(f"CL: Identified {suspected_noise_mask.sum()} / {n_samples} suspected noise")
        return suspected_noise_mask, pred_labels, pred_probs


class KNNSemanticVoting:
    """KNN: Semantic Voting"""
    
    def __init__(self, k=20, metric='euclidean', weight_eps=1e-6):
        self.k = k
        self.metric = metric
        self.weight_eps = weight_eps
        self.knn = None
    
    def fit(self, features):
        self.knn = NearestNeighbors(n_neighbors=self.k + 1, metric=self.metric)
        self.knn.fit(features)
    
    def predict_semantic_label(self, features, labels):
        distances, indices = self.knn.kneighbors(features)
        n_samples = len(labels)
        neighbor_labels = np.zeros(n_samples, dtype=int)
        neighbor_consistency = np.zeros(n_samples)
        
        for i in range(n_samples):
            neighbor_idx = indices[i]
            neighbor_d = distances[i]
            # æ’é™¤è‡ªèº«
            if neighbor_idx[0] == i and neighbor_d[0] <= self.weight_eps:
                neighbor_idx = neighbor_idx[1:self.k + 1]
                neighbor_d = neighbor_d[1:self.k + 1]
            else:
                neighbor_idx = neighbor_idx[:self.k]
                neighbor_d = neighbor_d[:self.k]
            
            neighbor_y = labels[neighbor_idx]
            w = 1.0 / (neighbor_d + self.weight_eps)
            vote_0 = w[neighbor_y == 0].sum()
            vote_1 = w[neighbor_y == 1].sum()
            total_w = vote_0 + vote_1
            
            neighbor_labels[i] = 0 if vote_0 > vote_1 else 1
            neighbor_consistency[i] = max(vote_0, vote_1) / total_w if total_w > 0 else 0.0
        
        self.last_neighbor_labels = neighbor_labels
        self.last_neighbor_consistency = neighbor_consistency
        return neighbor_labels, neighbor_consistency


class HybridCourt:
    """
    Hybrid Court v15: CL + AUM + KNN ä¸‰é‡æ ¡éªŒæ ‡ç­¾çŸ«æ­£ç­–ç•¥
    
    æ ¸å¿ƒåŸåˆ™: ä½¿ç”¨CLï¼ˆé™æ€ç‰¹å¾ï¼‰+ AUMï¼ˆåŠ¨æ€è®­ç»ƒç¨³å®šæ€§ï¼‰+ KNNï¼ˆè¯­ä¹‰æŠ•ç¥¨ï¼‰è¿›è¡Œæ ‡ç­¾çŸ«æ­£
    
    èåˆå†³ç­–é€»è¾‘ï¼š
    - Rule 1: ç¡®ä¿¡å¹²å‡€ (High Confidence Clean)
      * IF (CLç½®ä¿¡åº¦ > threshold) AND (AUM > 0) â†’ Keep (Tier 1)
      * è§£é‡Š: é•¿å¾—åƒï¼ˆCLé«˜ï¼‰ï¼Œè€Œä¸”å­¦å¾—å¿«ï¼ˆAUMæ­£ï¼‰ã€‚è¿™æ˜¯ç»å¯¹çš„å¹²å‡€æ ·æœ¬ã€‚
    
    - Rule 2: ç–‘ä¼¼å™ªå£° (Dirty Candidates)
      * IF (CLç½®ä¿¡åº¦ < threshold) OR (AUM < 0) â†’ Dirty Candidate
      * è§£é‡Š: åªè¦æœ‰ä¸€ä¸ªæŒ‡æ ‡è§‰å¾—å®ƒä¸å¯¹åŠ²ï¼Œå°±æŠŠå®ƒåˆ—å…¥å«Œç–‘åå•ã€‚
    
    - Rule 3: æ‹¯æ•‘/ç¿»è½¬ (Correction - ä»…é’ˆå¯¹ Dirty Candidate)
      * IF KNN Purity > 0.8 (ä¸”æŒ‡å‘åŒä¸€æ–°ç±»åˆ«) â†’ Flip (Tier 2)
      * ELSE â†’ Drop (Tier 3)
    """
    
    def __init__(self, config):
        self.config = config
        # ä¼˜åŒ–å»ºè®®2: ä¸ºCLåˆ›å»ºç‹¬ç«‹çš„æŠ•å½±å¤´
        use_cl_projection = getattr(config, 'USE_CL_PROJECTION_HEAD', True)
        feature_dim = getattr(config, 'FEATURE_DIM', getattr(config, 'OUTPUT_DIM', 32))
        # è‡ªåŠ¨æ£€æµ‹è®¾å¤‡
        import torch
        device = getattr(config, 'DEVICE', None)
        if device is None:
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        # å¦‚æœdeviceæ˜¯torch.deviceå¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if isinstance(device, torch.device):
            device = str(device)
        self.device = device
        
        self.cl = ConfidentLearning(
            n_folds=config.CL_K_FOLD,
            use_projection_head=use_cl_projection,
            feature_dim=feature_dim,
            device=device,
            config=config
        )
        
        self.knn = KNNSemanticVoting(
            k=config.KNN_NEIGHBORS,
            metric=getattr(config, 'KNN_METRIC', 'euclidean')
        )

    def correct_labels(self, features, noisy_labels, device='cpu', y_true=None):
        """
        ä¸¤é˜¶æ®µæ ‡ç­¾çŸ«æ­£ (CL + KNNï¼Œå»é™¤MADE)
        
        é˜¶æ®µ1: Keepå’ŒFlipå†³ç­–
            - Keepæ¡ä»¶:
              * æ¶æ„æ ‡ç­¾(label=1): CLè®¤ä¸ºä¸æ˜¯å™ªå£° ä¸” KNNä¸€è‡´æ€§ä¸ºhigh (>= high_threshold)
              * æ­£å¸¸æ ‡ç­¾(label=0): CLè®¤ä¸ºä¸æ˜¯å™ªå£° ä¸” KNNä¸€è‡´æ€§ > 0.55
            - Flipæ¡ä»¶:
              * CLè®¤ä¸ºæ˜¯å™ªå£° ä¸” KNNä¸æ”¯æŒå½“å‰æ ‡ç­¾ (neighbor_labels != current_label)
        
        é˜¶æ®µ2: é‡æ–°è®¡ç®—CLå’ŒKNNï¼ˆä½¿ç”¨é˜¶æ®µ1ç¿»è½¬åçš„æ–°æ ‡ç­¾ï¼‰ï¼ŒFlipå†³ç­–
            - Flipæ¡ä»¶:
              * CLè®¤ä¸ºæ˜¯å™ªå£° ä¸” KNNä¸æ”¯æŒå½“å‰æ ‡ç­¾ (neighbor_labels != current_label)
        
        KNNä¸€è‡´æ€§ç­‰çº§ï¼š
        - Low: < medium_threshold
        - Medium: >= medium_threshold ä¸” < high_threshold
        - High: >= high_threshold
        """
        cl_threshold = float(getattr(self.config, 'STAGE2_CL_THRESHOLD', 0.7))
        aum_threshold = float(getattr(self.config, 'STAGE2_AUM_THRESHOLD', 0.0))
        aum_epochs = int(getattr(self.config, 'AUM_EPOCHS', 30))
        aum_batch_size = int(getattr(self.config, 'AUM_BATCH_SIZE', 128))
        aum_lr = float(getattr(self.config, 'AUM_LR', 0.01))
        knn_purity_threshold = float(getattr(self.config, 'STAGE2_KNN_PURITY_THRESHOLD', 0.8))
        use_drop = bool(getattr(self.config, 'STAGE2_USE_DROP', False))

        # Phase1 / Phase2 ç­–ç•¥é˜ˆå€¼ï¼ˆå¯é€šè¿‡ config è¦†ç›–ï¼‰
        phase1_aggressive = bool(getattr(self.config, 'PHASE1_AGGRESSIVE', False))
        phase1_aggressive_malicious_aum_threshold = float(getattr(self.config, 'PHASE1_AGGRESSIVE_MALICIOUS_AUM_THRESHOLD', 0.05))
        phase1_aggressive_malicious_cl_threshold = float(getattr(self.config, 'PHASE1_AGGRESSIVE_MALICIOUS_CL_THRESHOLD', 0.6))
        phase1_aggressive_malicious_knn_cons_threshold = float(getattr(self.config, 'PHASE1_AGGRESSIVE_MALICIOUS_KNN_CONS_THRESHOLD', 0.6))
        phase1_aggressive_benign_aum_threshold = float(getattr(self.config, 'PHASE1_AGGRESSIVE_BENIGN_AUM_THRESHOLD', -0.05))
        phase1_aggressive_benign_knn_threshold = float(getattr(self.config, 'PHASE1_AGGRESSIVE_BENIGN_KNN_THRESHOLD', 0.55))

        phase1_malicious_aum_threshold = float(getattr(self.config, 'PHASE1_MALICIOUS_AUM_THRESHOLD', 0.0))
        phase1_malicious_knn_threshold = float(getattr(self.config, 'PHASE1_MALICIOUS_KNN_THRESHOLD', 0.7))
        phase1_malicious_cl_low = float(getattr(self.config, 'PHASE1_MALICIOUS_CL_LOW', 0.5))
        phase1_benign_aum_threshold = float(getattr(self.config, 'PHASE1_BENIGN_AUM_THRESHOLD', -0.5))
        phase1_benign_knn_threshold = float(getattr(self.config, 'PHASE1_BENIGN_KNN_THRESHOLD', 0.7))

        phase2_enable = bool(getattr(self.config, 'PHASE2_ENABLE', False))
        phase2_independent = bool(getattr(self.config, 'PHASE2_INDEPENDENT', True))
        # Phase2ç‹¬ç«‹ç¿»è½¬ç­–ç•¥å‚æ•°
        phase2_malicious_aum_threshold = float(getattr(self.config, 'PHASE2_MALICIOUS_AUM_THRESHOLD', 0.05))
        phase2_malicious_cl_threshold = float(getattr(self.config, 'PHASE2_MALICIOUS_CL_THRESHOLD', 0.65))
        phase2_malicious_knn_cons_threshold = float(getattr(self.config, 'PHASE2_MALICIOUS_KNN_CONS_THRESHOLD', 0.55))
        phase2_benign_aum_threshold = float(getattr(self.config, 'PHASE2_BENIGN_AUM_THRESHOLD', -0.2))
        phase2_benign_knn_threshold = float(getattr(self.config, 'PHASE2_BENIGN_KNN_THRESHOLD', 0.6))
        # æ—§ç­–ç•¥å‚æ•°ï¼ˆå…¼å®¹ï¼‰
        phase2_late_flip_aum_threshold = float(getattr(self.config, 'PHASE2_LATE_FLIP_AUM_THRESHOLD', -0.5))
        phase2_late_flip_knn_threshold = float(getattr(self.config, 'PHASE2_LATE_FLIP_KNN_THRESHOLD', 0.65))
        phase2_late_flip_cl_threshold = float(getattr(self.config, 'PHASE2_LATE_FLIP_CL_THRESHOLD', 0.4))
        phase2_undo_flip_aum_threshold = float(getattr(self.config, 'PHASE2_UNDO_FLIP_AUM_THRESHOLD', -0.8))
        phase2_undo_flip_cl_threshold = float(getattr(self.config, 'PHASE2_UNDO_FLIP_CL_THRESHOLD', 0.25))
        phase2_undo_flip_use_and = bool(getattr(self.config, 'PHASE2_UNDO_FLIP_USE_AND', False))
        phase2_undo_flip_p1_aum_hesitant = float(getattr(self.config, 'PHASE2_UNDO_FLIP_P1_AUM_HESITANT', -0.2))
        phase2_undo_flip_p1_aum_strong = float(getattr(self.config, 'PHASE2_UNDO_FLIP_P1_AUM_STRONG', -0.5))
        phase2_undo_flip_p2_aum_weak = float(getattr(self.config, 'PHASE2_UNDO_FLIP_P2_AUM_WEAK', 1.5))
        recompute_stage2_metrics = bool(getattr(self.config, 'RECOMPUTE_STAGE2_METRICS', True))

        clean_labels, action_mask, confidence, correction_weight, aum_scores, neighbor_consistency, pred_probs = correct_labels_cl_aum(
            self,
            features=np.asarray(features),
            noisy_labels=np.asarray(noisy_labels),
            device=str(device),
            y_true=y_true,
            cl_threshold=cl_threshold,
            aum_threshold=aum_threshold,
            aum_epochs=aum_epochs,
            aum_batch_size=aum_batch_size,
            aum_lr=aum_lr,
            knn_purity_threshold=knn_purity_threshold,
            use_drop=use_drop,
            phase1_aggressive=phase1_aggressive,
            phase1_aggressive_malicious_aum_threshold=phase1_aggressive_malicious_aum_threshold,
            phase1_aggressive_malicious_cl_threshold=phase1_aggressive_malicious_cl_threshold,
            phase1_aggressive_malicious_knn_cons_threshold=phase1_aggressive_malicious_knn_cons_threshold,
            phase1_aggressive_benign_aum_threshold=phase1_aggressive_benign_aum_threshold,
            phase1_aggressive_benign_knn_threshold=phase1_aggressive_benign_knn_threshold,
            phase1_malicious_aum_threshold=phase1_malicious_aum_threshold,
            phase1_malicious_knn_threshold=phase1_malicious_knn_threshold,
            phase1_malicious_cl_low=phase1_malicious_cl_low,
            phase1_benign_aum_threshold=phase1_benign_aum_threshold,
            phase1_benign_knn_threshold=phase1_benign_knn_threshold,
            phase2_enable=phase2_enable,
            phase2_independent=phase2_independent,
            phase2_malicious_aum_threshold=phase2_malicious_aum_threshold,
            phase2_malicious_cl_threshold=phase2_malicious_cl_threshold,
            phase2_malicious_knn_cons_threshold=phase2_malicious_knn_cons_threshold,
            phase2_benign_aum_threshold=phase2_benign_aum_threshold,
            phase2_benign_knn_threshold=phase2_benign_knn_threshold,
            phase2_late_flip_aum_threshold=phase2_late_flip_aum_threshold,
            phase2_late_flip_knn_threshold=phase2_late_flip_knn_threshold,
            phase2_late_flip_cl_threshold=phase2_late_flip_cl_threshold,
            phase2_undo_flip_aum_threshold=phase2_undo_flip_aum_threshold,
            phase2_undo_flip_cl_threshold=phase2_undo_flip_cl_threshold,
            phase2_undo_flip_use_and=phase2_undo_flip_use_and,
            phase2_undo_flip_p1_aum_hesitant=phase2_undo_flip_p1_aum_hesitant,
            phase2_undo_flip_p1_aum_strong=phase2_undo_flip_p1_aum_strong,
            phase2_undo_flip_p2_aum_weak=phase2_undo_flip_p2_aum_weak,
            recompute_stage2_metrics=recompute_stage2_metrics,
        )

        return clean_labels, action_mask, confidence, correction_weight, aum_scores, neighbor_consistency, pred_probs

    def _log_final_stats(self, n_samples, tier_info, action_mask, weights, logger):
        """è¾“å‡ºæœ€ç»ˆç»Ÿè®¡"""
        logger.info("\n" + "="*70)
        logger.info("ä¸‰é˜¶æ®µæ ‡ç­¾çŸ«æ­£ - æœ€ç»ˆç»“æœæ±‡æ€»")
        logger.info("="*70)
        
        tier_counts = {}
        for t in tier_info:
            tier_counts[t] = tier_counts.get(t, 0) + 1
        
        tier_order = [
            'Tier 1: Core', 'Tier 2: Flip', 'Tier 3: Keep',
            'Tier 4: Reweight', 'Dropped'
        ]
        
        weight_map = {
            'Tier 1: Core': weights['TIER_1_CORE'],
            'Tier 2: Flip': weights['TIER_2_FLIP'],
            'Tier 3: Keep': weights['TIER_3_KEEP_HI'],
            'Tier 4: Reweight': 0.5,
            'Dropped': 0.0
        }
        
        logger.info("\nğŸ“Š åˆ†çº§ç»Ÿè®¡:")
        for tier in tier_order:
            if tier in tier_counts:
                count = tier_counts[tier]
                weight = weight_map.get(tier, 0)
                logger.info(f"  {tier:30s}: {count:5d} ({100*count/n_samples:5.1f}%) | w={weight:.2f}")
        
        n_keep = (action_mask == 0).sum()
        n_flip = (action_mask == 1).sum()
        n_drop = (action_mask == 2).sum()
        n_rew = (action_mask == 3).sum()
        
        logger.info("\nğŸ“Š åŠ¨ä½œç»Ÿè®¡:")
        logger.info(f"  Keep:     {n_keep:5d} ({100*n_keep/n_samples:.1f}%)")
        logger.info(f"  Flip:     {n_flip:5d} ({100*n_flip/n_samples:.1f}%)")
        logger.info(f"  Drop:     {n_drop:5d} ({100*n_drop/n_samples:.1f}%)")
        logger.info(f"  Reweight: {n_rew:5d} ({100*n_rew/n_samples:.1f}%)")

    def _compute_tier_purity(self, clean_labels, y_true, tier_info, correction_weight, logger):
        """è®¡ç®—å„Tierçº¯åº¦"""
        logger.info("\nğŸ“Š å„Tierçº¯åº¦åˆ†æ:")
        
        tier_stats = {}
        for i, tier in enumerate(tier_info):
            if tier not in tier_stats:
                tier_stats[tier] = {'count': 0, 'correct': 0, 'weight': correction_weight[i]}
            tier_stats[tier]['count'] += 1
            if clean_labels[i] == y_true[i]:
                tier_stats[tier]['correct'] += 1
        
        tier_order = [
            'Tier 1: Core', 'Tier 2: Flip', 'Tier 3: Keep',
            'Tier 4: Reweight', 'Dropped'
        ]
        
        role_map = {
            'Tier 1: Core': '[å®šæµ·ç¥é’ˆ] ç»å¯¹çº¯å‡€åŸºçŸ³',
            'Tier 2: Flip': '[å¼ºåŠ›çº é”™] é«˜è´¨é‡ç¿»è½¬',
            'Tier 3: Keep': '[éš¾ä¾‹ç²¾å] ä¼˜è´¨ä¿æŒ',
            'Tier 4: Reweight': '[é•¿å°¾æ•°æ®] é™æƒä½¿ç”¨',
            'Dropped': '[å·²ä¸¢å¼ƒ] æ— æ³•æ‹¯æ•‘'
        }
        
        total_w_correct = 0
        total_w_count = 0
        
        logger.info("-" * 90)
        logger.info(f"{'Tier':<30s} | {'æƒé‡':>6s} | {'æ ·æœ¬æ•°':>8s} | {'çº¯åº¦':>8s} | {'å«å™ªæ•°':>8s} | è§’è‰²")
        logger.info("-" * 90)

        for tier in tier_order:
            if tier in tier_stats:
                s = tier_stats[tier]
                purity = 100 * s['correct'] / s['count'] if s['count'] > 0 else 0
                noise = s['count'] - s['correct']
                logger.info(f"{tier:<30s} | {s['weight']:>6.2f} | {s['count']:>8d} | {purity:>7.1f}% | {noise:>8d} | {role_map.get(tier, '')}")
                
                if 'Dropped' not in tier:
                    total_w_correct += s['correct'] * s['weight']
                    total_w_count += s['count'] * s['weight']
        
        logger.info("-" * 90)
        if total_w_count > 0:
            logger.info(f"ğŸ“ˆ åŠ æƒçº¯åº¦: {100 * total_w_correct / total_w_count:.2f}%")
